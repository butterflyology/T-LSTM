{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `jupyter notebook` for the `T-LSTM.py` example\n",
    "\n",
    "Modified from the [`T-LSTM`](https://github.com/illidanlab/T-LSTM/blob/master/main_AE.py) repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required packages. Note that this notebook uses the autoencode example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A toy example for clustering with 2-layer TLSTM auto-encoder\n",
    "# Inci M. Baytas, 2017\n",
    "# How to run: Directly run the main file: python main_AE.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import h5py\n",
    "\n",
    "from T_LSTM_AE import T_LSTM_AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a quick look at the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'#refs#', u'Assign', u'Data', u'Time']\n",
      "<HDF5 group \"/#refs#\" (16 members)>\n",
      "<HDF5 dataset \"Assign\": shape (1, 5), type \"|O\">\n",
      "<HDF5 dataset \"Data\": shape (1, 5), type \"|O\">\n",
      "<HDF5 dataset \"Time\": shape (1, 5), type \"|O\">\n"
     ]
    }
   ],
   "source": [
    "cluster_data = h5py.File('../data/Clustering_Data_1D.mat')\n",
    "print(list(cluster_data.keys()))\n",
    "\n",
    "for item in cluster_data.keys():\n",
    "    print(cluster_data[item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A synthetic data\n",
    "\n",
    "Data = []\n",
    "Time = []\n",
    "Assignments = []\n",
    "Target = []\n",
    "with h5py.File(\"../data/Clustering_Data_1D.mat\") as f:#\n",
    "    for column in f['Data']:\n",
    "        row_data = []\n",
    "        for row_number in range(len(column)):\n",
    "            row_data.append(f[column[row_number]][:])\n",
    "    Data.append(row_data)\n",
    "    for column in f['Time']:\n",
    "        row_data = []\n",
    "        for row_number in range(len(column)):\n",
    "            row_data.append(f[column[row_number]][:])\n",
    "    Time.append(row_data)\n",
    "    for column in f['Assign']:\n",
    "        row_data = []\n",
    "        for row_number in range(len(column)):\n",
    "            row_data.append(f[column[row_number]][:])\n",
    "    Assignments.append(row_data)\n",
    "\n",
    "cell_len = len(Data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(type(Data)) # The data object is a list\n",
    "print(len(Data))\n",
    "#print(Data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to generate batches of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(data, time, assign, index):\n",
    "    batch_data = np.transpose(data[0][index])\n",
    "    batch_time = np.transpose(time[0][index])\n",
    "    batch_assign = np.transpose(assign[0][index])\n",
    "    return batch_data, batch_time, batch_assign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set learning parameters\n",
    "learning_rate = 1e-3\n",
    "ae_iters = 2000 #Number of iterations (epochs)\n",
    "\n",
    "# set network parameters\n",
    "input_dim = np.size(Data[0][0], 0)\n",
    "hidden_dim = 8\n",
    "hidden_dim2 = 2\n",
    "hidden_dim3 = 8\n",
    "output_dim = hidden_dim\n",
    "output_dim2 = hidden_dim2\n",
    "output_dim3 = input_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model, set the loss function, optimizer, and initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_ae = T_LSTM_AE(input_dim, output_dim, output_dim2, output_dim3, hidden_dim, hidden_dim2, hidden_dim3)\n",
    "\n",
    "loss_ae = lstm_ae.get_reconstruction_loss()\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss_ae)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 324.265347\n",
      "Loss: 323.876810\n",
      "Loss: 323.489511\n",
      "Loss: 323.098788\n",
      "Loss: 322.699518\n",
      "Loss: 322.286002\n",
      "Loss: 321.852286\n",
      "Loss: 321.389377\n",
      "Loss: 320.883530\n",
      "Loss: 320.354929\n",
      "Loss: 319.812405\n",
      "Loss: 319.232227\n",
      "Loss: 318.602267\n",
      "Loss: 317.914642\n",
      "Loss: 317.159668\n",
      "Loss: 316.324347\n",
      "Loss: 315.393829\n",
      "Loss: 314.351016\n",
      "Loss: 313.177823\n",
      "Loss: 311.854285\n",
      "Loss: 310.365567\n",
      "Loss: 308.715613\n",
      "Loss: 306.913315\n",
      "Loss: 304.974423\n",
      "Loss: 302.939355\n",
      "Loss: 300.828775\n",
      "Loss: 298.678452\n",
      "Loss: 296.509674\n",
      "Loss: 294.340036\n",
      "Loss: 292.181171\n",
      "Loss: 290.035779\n",
      "Loss: 287.903769\n",
      "Loss: 285.796814\n",
      "Loss: 283.705472\n",
      "Loss: 281.595245\n",
      "Loss: 279.398386\n",
      "Loss: 277.425806\n",
      "Loss: 275.566742\n",
      "Loss: 273.746182\n",
      "Loss: 271.956924\n",
      "Loss: 270.228235\n",
      "Loss: 268.533459\n",
      "Loss: 266.871469\n",
      "Loss: 265.246820\n",
      "Loss: 263.656412\n",
      "Loss: 262.098129\n",
      "Loss: 260.571579\n",
      "Loss: 259.077783\n",
      "Loss: 257.614713\n",
      "Loss: 256.181305\n",
      "Loss: 254.776611\n",
      "Loss: 253.399625\n",
      "Loss: 252.049390\n",
      "Loss: 250.724896\n",
      "Loss: 249.425232\n",
      "Loss: 248.149384\n",
      "Loss: 246.897781\n",
      "Loss: 245.669089\n",
      "Loss: 244.462759\n",
      "Loss: 243.278250\n",
      "Loss: 242.114987\n",
      "Loss: 240.972247\n",
      "Loss: 239.849289\n",
      "Loss: 238.745413\n",
      "Loss: 237.659885\n",
      "Loss: 236.592081\n",
      "Loss: 235.541312\n",
      "Loss: 234.507016\n",
      "Loss: 233.488641\n",
      "Loss: 232.485660\n",
      "Loss: 231.497568\n",
      "Loss: 230.523907\n",
      "Loss: 229.564249\n",
      "Loss: 228.618201\n",
      "Loss: 227.685339\n",
      "Loss: 226.765347\n",
      "Loss: 225.857849\n",
      "Loss: 224.962549\n",
      "Loss: 224.079132\n",
      "Loss: 223.207300\n",
      "Loss: 222.346802\n",
      "Loss: 221.497382\n",
      "Loss: 220.658817\n",
      "Loss: 219.830850\n",
      "Loss: 219.013281\n",
      "Loss: 218.205896\n",
      "Loss: 217.408524\n",
      "Loss: 216.620972\n",
      "Loss: 215.843042\n",
      "Loss: 215.074548\n",
      "Loss: 214.315308\n",
      "Loss: 213.565167\n",
      "Loss: 212.823941\n",
      "Loss: 212.091486\n",
      "Loss: 211.367661\n",
      "Loss: 210.652289\n",
      "Loss: 209.945270\n",
      "Loss: 209.246432\n",
      "Loss: 208.555667\n",
      "Loss: 207.872830\n",
      "Loss: 207.197794\n",
      "Loss: 206.530453\n",
      "Loss: 205.870639\n",
      "Loss: 205.218222\n",
      "Loss: 204.573062\n",
      "Loss: 203.934970\n",
      "Loss: 203.303748\n",
      "Loss: 202.679144\n",
      "Loss: 202.060944\n",
      "Loss: 201.449005\n",
      "Loss: 200.843323\n",
      "Loss: 200.243997\n",
      "Loss: 199.651111\n",
      "Loss: 199.064752\n",
      "Loss: 198.484824\n",
      "Loss: 197.911201\n",
      "Loss: 197.343747\n",
      "Loss: 196.782259\n",
      "Loss: 196.226611\n",
      "Loss: 195.676723\n",
      "Loss: 195.132626\n",
      "Loss: 194.594398\n",
      "Loss: 194.061899\n",
      "Loss: 193.535101\n",
      "Loss: 193.013986\n",
      "Loss: 192.498434\n",
      "Loss: 191.988329\n",
      "Loss: 191.483479\n",
      "Loss: 190.983759\n",
      "Loss: 190.489050\n",
      "Loss: 189.999203\n",
      "Loss: 189.514062\n",
      "Loss: 189.033420\n",
      "Loss: 188.557108\n",
      "Loss: 188.084848\n",
      "Loss: 187.616321\n",
      "Loss: 187.151056\n",
      "Loss: 186.688382\n",
      "Loss: 186.226967\n",
      "Loss: 185.764766\n",
      "Loss: 185.300868\n",
      "Loss: 184.831827\n",
      "Loss: 184.364575\n",
      "Loss: 183.903429\n",
      "Loss: 183.445094\n",
      "Loss: 182.988248\n",
      "Loss: 182.534129\n",
      "Loss: 182.079021\n",
      "Loss: 181.625566\n",
      "Loss: 181.168509\n",
      "Loss: 180.708113\n",
      "Loss: 180.237750\n",
      "Loss: 179.738113\n",
      "Loss: 179.154147\n",
      "Loss: 178.310361\n",
      "Loss: 176.594064\n",
      "Loss: 174.920128\n",
      "Loss: 173.300243\n",
      "Loss: 171.578825\n",
      "Loss: 170.882507\n",
      "Loss: 169.969591\n",
      "Loss: 169.355511\n",
      "Loss: 168.607286\n",
      "Loss: 167.988338\n",
      "Loss: 167.373579\n",
      "Loss: 166.750040\n",
      "Loss: 166.167662\n",
      "Loss: 165.556731\n",
      "Loss: 164.982523\n",
      "Loss: 164.403247\n",
      "Loss: 163.841078\n",
      "Loss: 163.278529\n",
      "Loss: 162.723299\n",
      "Loss: 162.173409\n",
      "Loss: 161.628773\n",
      "Loss: 161.090506\n",
      "Loss: 160.555132\n",
      "Loss: 160.024792\n",
      "Loss: 159.498036\n",
      "Loss: 158.975996\n",
      "Loss: 158.459592\n",
      "Loss: 157.945921\n",
      "Loss: 157.438242\n",
      "Loss: 156.931323\n",
      "Loss: 156.431763\n",
      "Loss: 155.932510\n",
      "Loss: 155.440283\n",
      "Loss: 154.948503\n",
      "Loss: 154.462625\n",
      "Loss: 153.979021\n",
      "Loss: 153.499117\n",
      "Loss: 153.023088\n",
      "Loss: 152.549605\n",
      "Loss: 152.080193\n",
      "Loss: 151.613745\n",
      "Loss: 151.150424\n",
      "Loss: 150.690736\n",
      "Loss: 150.233745\n",
      "Loss: 149.779889\n",
      "Loss: 149.329478\n",
      "Loss: 148.881572\n",
      "Loss: 148.436597\n",
      "Loss: 147.994966\n",
      "Loss: 147.555537\n",
      "Loss: 147.118706\n",
      "Loss: 146.685301\n",
      "Loss: 146.253802\n",
      "Loss: 145.824178\n",
      "Loss: 145.398216\n",
      "Loss: 144.974242\n",
      "Loss: 144.550992\n",
      "Loss: 144.131410\n",
      "Loss: 143.714903\n",
      "Loss: 143.297867\n",
      "Loss: 142.883604\n",
      "Loss: 142.474377\n",
      "Loss: 142.064520\n",
      "Loss: 141.655328\n",
      "Loss: 141.252191\n",
      "Loss: 140.850375\n",
      "Loss: 140.447614\n",
      "Loss: 140.049283\n",
      "Loss: 139.654500\n",
      "Loss: 139.259802\n",
      "Loss: 138.866840\n",
      "Loss: 138.477277\n",
      "Loss: 138.090004\n",
      "Loss: 137.703801\n",
      "Loss: 137.319447\n",
      "Loss: 136.937825\n",
      "Loss: 136.558095\n",
      "Loss: 136.179747\n",
      "Loss: 135.803352\n",
      "Loss: 135.429050\n",
      "Loss: 135.056453\n",
      "Loss: 134.685420\n",
      "Loss: 134.316226\n",
      "Loss: 133.948820\n",
      "Loss: 133.583009\n",
      "Loss: 133.218829\n",
      "Loss: 132.856303\n",
      "Loss: 132.495409\n",
      "Loss: 132.136032\n",
      "Loss: 131.778197\n",
      "Loss: 131.421907\n",
      "Loss: 131.067139\n",
      "Loss: 130.713884\n",
      "Loss: 130.362196\n",
      "Loss: 130.012144\n",
      "Loss: 129.663771\n",
      "Loss: 129.317140\n",
      "Loss: 128.972223\n",
      "Loss: 128.629002\n",
      "Loss: 128.287405\n",
      "Loss: 127.947331\n",
      "Loss: 127.608701\n",
      "Loss: 127.271481\n",
      "Loss: 126.935670\n",
      "Loss: 126.601279\n",
      "Loss: 126.268326\n",
      "Loss: 125.936830\n",
      "Loss: 125.606770\n",
      "Loss: 125.278146\n",
      "Loss: 124.950925\n",
      "Loss: 124.625076\n",
      "Loss: 124.300542\n",
      "Loss: 123.977289\n",
      "Loss: 123.655284\n",
      "Loss: 123.334496\n",
      "Loss: 123.014923\n",
      "Loss: 122.696542\n",
      "Loss: 122.379340\n",
      "Loss: 122.063329\n",
      "Loss: 121.748486\n",
      "Loss: 121.434824\n",
      "Loss: 121.122324\n",
      "Loss: 120.810970\n",
      "Loss: 120.500757\n",
      "Loss: 120.191675\n",
      "Loss: 119.883720\n",
      "Loss: 119.576837\n",
      "Loss: 119.270985\n",
      "Loss: 118.966080\n",
      "Loss: 118.662080\n",
      "Loss: 118.358955\n",
      "Loss: 118.056696\n",
      "Loss: 117.755293\n",
      "Loss: 117.454729\n",
      "Loss: 117.155013\n",
      "Loss: 116.856187\n",
      "Loss: 116.558362\n",
      "Loss: 116.261635\n",
      "Loss: 115.966104\n",
      "Loss: 115.671762\n",
      "Loss: 115.378500\n",
      "Loss: 115.086125\n",
      "Loss: 114.794345\n",
      "Loss: 114.503113\n",
      "Loss: 114.213052\n",
      "Loss: 113.924927\n",
      "Loss: 113.638715\n",
      "Loss: 113.353850\n",
      "Loss: 113.070135\n",
      "Loss: 112.786667\n",
      "Loss: 112.501414\n",
      "Loss: 112.217113\n",
      "Loss: 111.938033\n",
      "Loss: 111.661790\n",
      "Loss: 111.385189\n",
      "Loss: 111.109364\n",
      "Loss: 110.831837\n",
      "Loss: 110.546983\n",
      "Loss: 110.269991\n",
      "Loss: 110.001346\n",
      "Loss: 109.731201\n",
      "Loss: 109.459232\n",
      "Loss: 109.184818\n",
      "Loss: 108.902647\n",
      "Loss: 108.628847\n",
      "Loss: 108.362194\n",
      "Loss: 108.092913\n",
      "Loss: 107.819463\n",
      "Loss: 107.544113\n",
      "Loss: 107.269751\n",
      "Loss: 106.998679\n",
      "Loss: 106.728851\n",
      "Loss: 106.457974\n",
      "Loss: 106.185406\n",
      "Loss: 105.908648\n",
      "Loss: 105.630907\n",
      "Loss: 105.362811\n",
      "Loss: 105.103256\n",
      "Loss: 104.843848\n",
      "Loss: 104.579312\n",
      "Loss: 104.303564\n",
      "Loss: 104.023476\n",
      "Loss: 103.760143\n",
      "Loss: 103.505419\n",
      "Loss: 103.250439\n",
      "Loss: 102.988869\n",
      "Loss: 102.714880\n",
      "Loss: 102.445975\n",
      "Loss: 102.190012\n",
      "Loss: 101.936790\n",
      "Loss: 101.683700\n",
      "Loss: 101.422652\n",
      "Loss: 101.157639\n",
      "Loss: 100.900755\n",
      "Loss: 100.649708\n",
      "Loss: 100.399803\n",
      "Loss: 100.146897\n",
      "Loss: 99.889835\n",
      "Loss: 99.635690\n",
      "Loss: 99.386574\n",
      "Loss: 99.139012\n",
      "Loss: 98.889774\n",
      "Loss: 98.638842\n",
      "Loss: 98.389444\n",
      "Loss: 98.142232\n",
      "Loss: 97.895315\n",
      "Loss: 97.647829\n",
      "Loss: 97.400755\n",
      "Loss: 97.154542\n",
      "Loss: 96.908723\n",
      "Loss: 96.663005\n",
      "Loss: 96.417610\n",
      "Loss: 96.172841\n",
      "Loss: 95.928807\n",
      "Loss: 95.685548\n",
      "Loss: 95.443096\n",
      "Loss: 95.201475\n",
      "Loss: 94.960593\n",
      "Loss: 94.720352\n",
      "Loss: 94.480748\n",
      "Loss: 94.241888\n",
      "Loss: 94.003828\n",
      "Loss: 93.766551\n",
      "Loss: 93.529996\n",
      "Loss: 93.294160\n",
      "Loss: 93.059092\n",
      "Loss: 92.824747\n",
      "Loss: 92.590989\n",
      "Loss: 92.357752\n",
      "Loss: 92.125011\n",
      "Loss: 91.892847\n",
      "Loss: 91.661269\n",
      "Loss: 91.430245\n",
      "Loss: 91.199702\n",
      "Loss: 90.969627\n",
      "Loss: 90.740082\n",
      "Loss: 90.511068\n",
      "Loss: 90.282477\n",
      "Loss: 90.054221\n",
      "Loss: 89.826350\n",
      "Loss: 89.599127\n",
      "Loss: 89.372714\n",
      "Loss: 89.147019\n",
      "Loss: 88.921703\n",
      "Loss: 88.696550\n",
      "Loss: 88.471706\n",
      "Loss: 88.247589\n",
      "Loss: 88.024530\n",
      "Loss: 87.802387\n",
      "Loss: 87.580670\n",
      "Loss: 87.358932\n",
      "Loss: 87.137302\n",
      "Loss: 86.916513\n",
      "Loss: 86.697384\n",
      "Loss: 86.479949\n",
      "Loss: 86.262964\n",
      "Loss: 86.044952\n",
      "Loss: 85.825919\n",
      "Loss: 85.607354\n",
      "Loss: 85.391325\n",
      "Loss: 85.179764\n",
      "Loss: 84.971122\n",
      "Loss: 84.759462\n",
      "Loss: 84.542912\n",
      "Loss: 84.326157\n",
      "Loss: 84.109904\n",
      "Loss: 83.898038\n",
      "Loss: 83.704646\n",
      "Loss: 83.520497\n",
      "Loss: 83.309386\n",
      "Loss: 83.090230\n",
      "Loss: 82.890237\n",
      "Loss: 82.663017\n",
      "Loss: 82.470667\n",
      "Loss: 82.325182\n",
      "Loss: 82.116527\n",
      "Loss: 81.897189\n",
      "Loss: 81.677821\n",
      "Loss: 81.450559\n",
      "Loss: 81.269836\n",
      "Loss: 81.077105\n",
      "Loss: 80.859725\n",
      "Loss: 80.640376\n",
      "Loss: 80.431129\n",
      "Loss: 80.250880\n",
      "Loss: 80.057603\n",
      "Loss: 79.850040\n",
      "Loss: 79.636012\n",
      "Loss: 79.434565\n",
      "Loss: 79.252753\n",
      "Loss: 79.059429\n",
      "Loss: 78.857117\n",
      "Loss: 78.646276\n",
      "Loss: 78.457007\n",
      "Loss: 78.279670\n",
      "Loss: 78.084600\n",
      "Loss: 77.883192\n",
      "Loss: 77.673841\n",
      "Loss: 77.494530\n",
      "Loss: 77.317681\n",
      "Loss: 77.117571\n",
      "Loss: 76.911358\n",
      "Loss: 76.714591\n",
      "Loss: 76.538643\n",
      "Loss: 76.353921\n",
      "Loss: 76.150702\n",
      "Loss: 75.952158\n",
      "Loss: 75.769941\n",
      "Loss: 75.589169\n",
      "Loss: 75.397256\n",
      "Loss: 75.201967\n",
      "Loss: 75.011623\n",
      "Loss: 74.832716\n",
      "Loss: 74.649412\n",
      "Loss: 74.460097\n",
      "Loss: 74.268918\n",
      "Loss: 74.084749\n",
      "Loss: 73.907006\n",
      "Loss: 73.724655\n",
      "Loss: 73.538053\n",
      "Loss: 73.349939\n",
      "Loss: 73.171599\n",
      "Loss: 72.995494\n",
      "Loss: 72.814973\n",
      "Loss: 72.629671\n",
      "Loss: 72.445674\n",
      "Loss: 72.272462\n",
      "Loss: 72.098567\n",
      "Loss: 71.920209\n",
      "Loss: 71.735049\n",
      "Loss: 71.555931\n",
      "Loss: 71.387624\n",
      "Loss: 71.216779\n",
      "Loss: 71.040163\n",
      "Loss: 70.854066\n",
      "Loss: 70.680702\n",
      "Loss: 70.517843\n",
      "Loss: 70.350892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 70.174819\n",
      "Loss: 69.986118\n",
      "Loss: 69.821397\n",
      "Loss: 69.664719\n",
      "Loss: 69.502864\n",
      "Loss: 69.324070\n",
      "Loss: 69.131625\n",
      "Loss: 68.983391\n",
      "Loss: 68.831953\n",
      "Loss: 68.676620\n",
      "Loss: 68.485007\n",
      "Loss: 68.299538\n",
      "Loss: 68.172790\n",
      "Loss: 68.032430\n",
      "Loss: 67.862775\n",
      "Loss: 67.650156\n",
      "Loss: 67.520357\n",
      "Loss: 67.396899\n",
      "Loss: 67.223969\n",
      "Loss: 67.010822\n",
      "Loss: 66.833910\n",
      "Loss: 66.729905\n",
      "Loss: 66.575207\n",
      "Loss: 66.360774\n",
      "Loss: 66.182341\n",
      "Loss: 66.081309\n",
      "Loss: 65.910822\n",
      "Loss: 65.700993\n",
      "Loss: 65.533912\n",
      "Loss: 65.425594\n",
      "Loss: 65.250050\n",
      "Loss: 65.055981\n",
      "Loss: 64.902839\n",
      "Loss: 64.783131\n",
      "Loss: 64.611600\n",
      "Loss: 64.428226\n",
      "Loss: 64.279610\n",
      "Loss: 64.154380\n",
      "Loss: 63.989867\n",
      "Loss: 63.808746\n",
      "Loss: 63.662012\n",
      "Loss: 63.541495\n",
      "Loss: 63.380218\n",
      "Loss: 63.195728\n",
      "Loss: 63.051256\n",
      "Loss: 62.939105\n",
      "Loss: 62.781780\n",
      "Loss: 62.590484\n",
      "Loss: 62.446872\n",
      "Loss: 62.346116\n",
      "Loss: 62.196162\n",
      "Loss: 61.995261\n",
      "Loss: 61.848985\n",
      "Loss: 61.759792\n",
      "Loss: 61.623917\n",
      "Loss: 61.411829\n",
      "Loss: 61.257137\n",
      "Loss: 61.179158\n",
      "Loss: 61.061501\n",
      "Loss: 60.836002\n",
      "Loss: 60.671591\n",
      "Loss: 60.602532\n",
      "Loss: 60.491188\n",
      "Loss: 60.253674\n",
      "Loss: 60.091774\n",
      "Loss: 60.023763\n",
      "Loss: 59.885168\n",
      "Loss: 59.660879\n",
      "Loss: 59.523703\n",
      "Loss: 59.441535\n",
      "Loss: 59.263244\n",
      "Loss: 59.086452\n",
      "Loss: 58.972324\n",
      "Loss: 58.846070\n",
      "Loss: 58.677378\n",
      "Loss: 58.535046\n",
      "Loss: 58.408023\n",
      "Loss: 58.268710\n",
      "Loss: 58.120894\n",
      "Loss: 57.979588\n",
      "Loss: 57.847614\n",
      "Loss: 57.712785\n",
      "Loss: 57.568283\n",
      "Loss: 57.426129\n",
      "Loss: 57.293889\n",
      "Loss: 57.162164\n",
      "Loss: 57.022051\n",
      "Loss: 56.878073\n",
      "Loss: 56.742966\n",
      "Loss: 56.614220\n",
      "Loss: 56.481538\n",
      "Loss: 56.339637\n",
      "Loss: 56.197487\n",
      "Loss: 56.066147\n",
      "Loss: 55.938659\n",
      "Loss: 55.808893\n",
      "Loss: 55.670232\n",
      "Loss: 55.526035\n",
      "Loss: 55.392411\n",
      "Loss: 55.265319\n",
      "Loss: 55.139931\n",
      "Loss: 55.017878\n",
      "Loss: 54.880975\n",
      "Loss: 54.727614\n",
      "Loss: 54.594518\n",
      "Loss: 54.479274\n",
      "Loss: 54.358597\n",
      "Loss: 54.257907\n",
      "Loss: 54.154374\n",
      "Loss: 53.948343\n",
      "Loss: 53.826571\n",
      "Loss: 53.752982\n",
      "Loss: 53.617997\n",
      "Loss: 53.552213\n",
      "Loss: 53.341085\n",
      "Loss: 53.176226\n",
      "Loss: 53.127379\n",
      "Loss: 52.989744\n",
      "Loss: 52.869290\n",
      "Loss: 52.657252\n",
      "Loss: 52.547103\n",
      "Loss: 52.472676\n",
      "Loss: 52.350306\n",
      "Loss: 52.171525\n",
      "Loss: 52.013691\n",
      "Loss: 51.929948\n",
      "Loss: 51.832381\n",
      "Loss: 51.701799\n",
      "Loss: 51.518733\n",
      "Loss: 51.405750\n",
      "Loss: 51.317220\n",
      "Loss: 51.206340\n",
      "Loss: 51.043410\n",
      "Loss: 50.898962\n",
      "Loss: 50.803825\n",
      "Loss: 50.705376\n",
      "Loss: 50.568621\n",
      "Loss: 50.411971\n",
      "Loss: 50.302093\n",
      "Loss: 50.207445\n",
      "Loss: 50.089312\n",
      "Loss: 49.936445\n",
      "Loss: 49.812714\n",
      "Loss: 49.715727\n",
      "Loss: 49.608938\n",
      "Loss: 49.466255\n",
      "Loss: 49.334435\n",
      "Loss: 49.232273\n",
      "Loss: 49.130912\n",
      "Loss: 48.999446\n",
      "Loss: 48.865512\n",
      "Loss: 48.757259\n",
      "Loss: 48.657370\n",
      "Loss: 48.536366\n",
      "Loss: 48.404607\n",
      "Loss: 48.290849\n",
      "Loss: 48.189913\n",
      "Loss: 48.077716\n",
      "Loss: 47.950982\n",
      "Loss: 47.833223\n",
      "Loss: 47.729756\n",
      "Loss: 47.624014\n",
      "Loss: 47.504082\n",
      "Loss: 47.384589\n",
      "Loss: 47.277887\n",
      "Loss: 47.175812\n",
      "Loss: 47.063190\n",
      "Loss: 46.944678\n",
      "Loss: 46.834986\n",
      "Loss: 46.733903\n",
      "Loss: 46.627645\n",
      "Loss: 46.512498\n",
      "Loss: 46.401102\n",
      "Loss: 46.299207\n",
      "Loss: 46.197254\n",
      "Loss: 46.086713\n",
      "Loss: 45.975464\n",
      "Loss: 45.872207\n",
      "Loss: 45.772343\n",
      "Loss: 45.666299\n",
      "Loss: 45.556780\n",
      "Loss: 45.452647\n",
      "Loss: 45.353374\n",
      "Loss: 45.250792\n",
      "Loss: 45.143856\n",
      "Loss: 45.039720\n",
      "Loss: 44.940415\n",
      "Loss: 44.840146\n",
      "Loss: 44.735912\n",
      "Loss: 44.632516\n",
      "Loss: 44.533145\n",
      "Loss: 44.434302\n",
      "Loss: 44.332454\n",
      "Loss: 44.230251\n",
      "Loss: 44.131014\n",
      "Loss: 44.033078\n",
      "Loss: 43.933171\n",
      "Loss: 43.832315\n",
      "Loss: 43.733439\n",
      "Loss: 43.636142\n",
      "Loss: 43.537721\n",
      "Loss: 43.438181\n",
      "Loss: 43.339835\n",
      "Loss: 43.243007\n",
      "Loss: 43.145684\n",
      "Loss: 43.047289\n",
      "Loss: 42.949496\n",
      "Loss: 42.853004\n",
      "Loss: 42.756424\n",
      "Loss: 42.658932\n",
      "Loss: 42.561610\n",
      "Loss: 42.465323\n",
      "Loss: 42.369260\n",
      "Loss: 42.272484\n",
      "Loss: 42.175558\n",
      "Loss: 42.079514\n",
      "Loss: 41.984083\n",
      "Loss: 41.888131\n",
      "Loss: 41.791674\n",
      "Loss: 41.696062\n",
      "Loss: 41.601811\n",
      "Loss: 41.507351\n",
      "Loss: 41.411439\n",
      "Loss: 41.315631\n",
      "Loss: 41.222581\n",
      "Loss: 41.130856\n",
      "Loss: 41.036337\n",
      "Loss: 40.938674\n",
      "Loss: 40.844094\n",
      "Loss: 40.755437\n",
      "Loss: 40.665433\n",
      "Loss: 40.566650\n",
      "Loss: 40.461696\n",
      "Loss: 40.363839\n",
      "Loss: 40.274551\n",
      "Loss: 40.186414\n",
      "Loss: 40.090868\n",
      "Loss: 39.985211\n",
      "Loss: 39.881775\n",
      "Loss: 39.788976\n",
      "Loss: 39.703651\n",
      "Loss: 39.622915\n",
      "Loss: 39.539468\n",
      "Loss: 39.436447\n",
      "Loss: 39.317266\n",
      "Loss: 39.222462\n",
      "Loss: 39.154671\n",
      "Loss: 39.105804\n",
      "Loss: 39.108118\n",
      "Loss: 39.000328\n",
      "Loss: 38.775419\n",
      "Loss: 38.818638\n",
      "Loss: 38.763089\n",
      "Loss: 38.734762\n",
      "Loss: 38.497881\n",
      "Loss: 38.491755\n",
      "Loss: 38.605093\n",
      "Loss: 38.360240\n",
      "Loss: 38.178028\n",
      "Loss: 38.061667\n",
      "Loss: 37.978847\n",
      "Loss: 37.785168\n",
      "Loss: 37.725257\n",
      "Loss: 37.651963\n",
      "Loss: 37.509847\n",
      "Loss: 37.430365\n",
      "Loss: 37.351254\n",
      "Loss: 37.239194\n",
      "Loss: 37.153426\n",
      "Loss: 37.072459\n",
      "Loss: 36.970830\n",
      "Loss: 36.872986\n",
      "Loss: 36.788937\n",
      "Loss: 36.694287\n",
      "Loss: 36.593505\n",
      "Loss: 36.497276\n",
      "Loss: 36.407195\n",
      "Loss: 36.310034\n",
      "Loss: 36.206218\n",
      "Loss: 36.113494\n",
      "Loss: 36.029833\n",
      "Loss: 35.937596\n",
      "Loss: 35.835554\n",
      "Loss: 35.741859\n",
      "Loss: 35.660697\n",
      "Loss: 35.577937\n",
      "Loss: 35.480233\n",
      "Loss: 35.376466\n",
      "Loss: 35.289971\n",
      "Loss: 35.218285\n",
      "Loss: 35.140638\n",
      "Loss: 35.035423\n",
      "Loss: 34.925263\n",
      "Loss: 34.848223\n",
      "Loss: 34.789997\n",
      "Loss: 34.723146\n",
      "Loss: 34.603769\n",
      "Loss: 34.482025\n",
      "Loss: 34.425085\n",
      "Loss: 34.389109\n",
      "Loss: 34.344370\n",
      "Loss: 34.183978\n",
      "Loss: 34.065285\n",
      "Loss: 34.068036\n",
      "Loss: 34.079882\n",
      "Loss: 34.009114\n",
      "Loss: 33.745757\n",
      "Loss: 33.796324\n",
      "Loss: 33.868175\n",
      "Loss: 33.761503\n",
      "Loss: 33.470029\n",
      "Loss: 33.452172\n",
      "Loss: 33.504720\n",
      "Loss: 33.208269\n",
      "Loss: 33.093837\n",
      "Loss: 33.160265\n",
      "Loss: 32.994051\n",
      "Loss: 32.821019\n",
      "Loss: 32.854457\n",
      "Loss: 32.793937\n",
      "Loss: 32.589633\n",
      "Loss: 32.549942\n",
      "Loss: 32.586456\n",
      "Loss: 32.338717\n",
      "Loss: 32.261675\n",
      "Loss: 32.340395\n",
      "Loss: 32.123579\n",
      "Loss: 32.010351\n",
      "Loss: 32.055098\n",
      "Loss: 31.911633\n",
      "Loss: 31.753539\n",
      "Loss: 31.752655\n",
      "Loss: 31.676908\n",
      "Loss: 31.502025\n",
      "Loss: 31.459962\n",
      "Loss: 31.421941\n",
      "Loss: 31.274452\n",
      "Loss: 31.191536\n",
      "Loss: 31.150827\n",
      "Loss: 31.054280\n",
      "Loss: 30.951416\n",
      "Loss: 30.883015\n",
      "Loss: 30.813288\n",
      "Loss: 30.726966\n",
      "Loss: 30.639162\n",
      "Loss: 30.560530\n",
      "Loss: 30.488514\n",
      "Loss: 30.410892\n",
      "Loss: 30.325160\n",
      "Loss: 30.243305\n",
      "Loss: 30.169752\n",
      "Loss: 30.096701\n",
      "Loss: 30.016869\n",
      "Loss: 29.932937\n",
      "Loss: 29.855199\n",
      "Loss: 29.784462\n",
      "Loss: 29.712015\n",
      "Loss: 29.630882\n",
      "Loss: 29.547651\n",
      "Loss: 29.473840\n",
      "Loss: 29.406200\n",
      "Loss: 29.334766\n",
      "Loss: 29.251878\n",
      "Loss: 29.168534\n",
      "Loss: 29.098866\n",
      "Loss: 29.035009\n",
      "Loss: 28.966247\n",
      "Loss: 28.880412\n",
      "Loss: 28.794313\n",
      "Loss: 28.730562\n",
      "Loss: 28.671749\n",
      "Loss: 28.610782\n",
      "Loss: 28.522688\n",
      "Loss: 28.424314\n",
      "Loss: 28.372929\n",
      "Loss: 28.321033\n",
      "Loss: 28.281301\n",
      "Loss: 28.217088\n",
      "Loss: 28.074159\n",
      "Loss: 28.036744\n",
      "Loss: 28.032345\n",
      "Loss: 27.992466\n",
      "Loss: 28.067764\n",
      "Loss: 27.852201\n",
      "Loss: 27.730933\n",
      "Loss: 27.834052\n",
      "Loss: 27.792377\n",
      "Loss: 27.798807\n",
      "Loss: 27.469811\n",
      "Loss: 27.437986\n",
      "Loss: 27.394462\n",
      "Loss: 27.255733\n",
      "Loss: 27.118873\n",
      "Loss: 27.044081\n",
      "Loss: 26.978630\n",
      "Loss: 26.883958\n",
      "Loss: 26.815401\n",
      "Loss: 26.762724\n",
      "Loss: 26.682471\n",
      "Loss: 26.603526\n",
      "Loss: 26.550114\n",
      "Loss: 26.490980\n",
      "Loss: 26.407520\n",
      "Loss: 26.331708\n",
      "Loss: 26.279457\n",
      "Loss: 26.220834\n",
      "Loss: 26.144589\n",
      "Loss: 26.062333\n",
      "Loss: 26.004201\n",
      "Loss: 25.952101\n",
      "Loss: 25.889919\n",
      "Loss: 25.812036\n",
      "Loss: 25.725908\n",
      "Loss: 25.688253\n",
      "Loss: 25.642486\n",
      "Loss: 25.606293\n",
      "Loss: 25.518944\n",
      "Loss: 25.403917\n",
      "Loss: 25.473174\n",
      "Loss: 25.415187\n",
      "Loss: 25.521318\n",
      "Loss: 25.273060\n",
      "Loss: 25.231566\n",
      "Loss: 25.242760\n",
      "Loss: 25.169985\n",
      "Loss: 25.049056\n",
      "Loss: 24.860339\n",
      "Loss: 24.870611\n",
      "Loss: 24.794308\n",
      "Loss: 24.672910\n",
      "Loss: 24.579149\n",
      "Loss: 24.568095\n",
      "Loss: 24.532191\n",
      "Loss: 24.412084\n",
      "Loss: 24.330465\n",
      "Loss: 24.340032\n",
      "Loss: 24.328074\n",
      "Loss: 24.210748\n",
      "Loss: 24.088940\n",
      "Loss: 24.147354\n",
      "Loss: 24.148600\n",
      "Loss: 24.083601\n",
      "Loss: 23.871212\n",
      "Loss: 23.982544\n",
      "Loss: 24.006587\n",
      "Loss: 23.896176\n",
      "Loss: 23.664996\n",
      "Loss: 23.708464\n",
      "Loss: 23.763268\n",
      "Loss: 23.521019\n",
      "Loss: 23.414578\n",
      "Loss: 23.456380\n",
      "Loss: 23.432186\n",
      "Loss: 23.342954\n",
      "Loss: 23.193899\n",
      "Loss: 23.249169\n",
      "Loss: 23.050692\n",
      "Loss: 22.980594\n",
      "Loss: 22.938341\n",
      "Loss: 22.877160\n",
      "Loss: 22.787263\n",
      "Loss: 22.723898\n",
      "Loss: 22.719486\n",
      "Loss: 22.604005\n",
      "Loss: 22.547475\n",
      "Loss: 22.514845\n",
      "Loss: 22.507282\n",
      "Loss: 22.372793\n",
      "Loss: 22.337124\n",
      "Loss: 22.356692\n",
      "Loss: 22.293709\n",
      "Loss: 22.188844\n",
      "Loss: 22.151391\n",
      "Loss: 22.255184\n",
      "Loss: 22.041061\n",
      "Loss: 21.976925\n",
      "Loss: 21.949446\n",
      "Loss: 22.008009\n",
      "Loss: 21.831022\n",
      "Loss: 21.751999\n",
      "Loss: 21.846390\n",
      "Loss: 21.632843\n",
      "Loss: 21.577542\n",
      "Loss: 21.514806\n",
      "Loss: 21.545008\n",
      "Loss: 21.387802\n",
      "Loss: 21.327208\n",
      "Loss: 21.351963\n",
      "Loss: 21.223784\n",
      "Loss: 21.157200\n",
      "Loss: 21.112565\n",
      "Loss: 21.136587\n",
      "Loss: 20.988429\n",
      "Loss: 20.942364\n",
      "Loss: 20.956345\n",
      "Loss: 20.885101\n",
      "Loss: 20.786230\n",
      "Loss: 20.746229\n",
      "Loss: 20.834228\n",
      "Loss: 20.638780\n",
      "Loss: 20.575776\n",
      "Loss: 20.567690\n",
      "Loss: 20.586497\n",
      "Loss: 20.442744\n",
      "Loss: 20.394972\n",
      "Loss: 20.511538\n",
      "Loss: 20.296224\n",
      "Loss: 20.219931\n",
      "Loss: 20.184579\n",
      "Loss: 20.254107\n",
      "Loss: 20.078051\n",
      "Loss: 20.011987\n",
      "Loss: 20.104566\n",
      "Loss: 19.897781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 19.833032\n",
      "Loss: 19.815223\n",
      "Loss: 19.787827\n",
      "Loss: 19.674654\n",
      "Loss: 19.624359\n",
      "Loss: 19.657311\n",
      "Loss: 19.529139\n",
      "Loss: 19.461316\n",
      "Loss: 19.448704\n",
      "Loss: 19.427154\n",
      "Loss: 19.316565\n",
      "Loss: 19.270588\n",
      "Loss: 19.310323\n",
      "Loss: 19.195494\n",
      "Loss: 19.107721\n",
      "Loss: 19.096976\n",
      "Loss: 19.141780\n",
      "Loss: 18.987467\n",
      "Loss: 18.930242\n",
      "Loss: 19.011513\n",
      "Loss: 18.881527\n",
      "Loss: 18.780822\n",
      "Loss: 18.792074\n",
      "Loss: 18.930016\n",
      "Loss: 18.734465\n",
      "Loss: 18.646983\n",
      "Loss: 18.766396\n",
      "Loss: 18.711847\n",
      "Loss: 18.692476\n",
      "Loss: 18.577180\n",
      "Loss: 18.935591\n",
      "Loss: 18.664779\n",
      "Loss: 18.599885\n",
      "Loss: 18.854764\n",
      "Loss: 18.638968\n",
      "Loss: 18.709585\n",
      "Loss: 18.740004\n",
      "Loss: 18.528700\n",
      "Loss: 18.472680\n",
      "Loss: 18.347241\n",
      "Loss: 18.273594\n",
      "Loss: 18.261537\n",
      "Loss: 18.093150\n",
      "Loss: 18.133060\n",
      "Loss: 18.055681\n",
      "Loss: 18.167420\n",
      "Loss: 18.144112\n",
      "Loss: 18.054111\n",
      "Loss: 18.166515\n",
      "Loss: 18.231954\n",
      "Loss: 18.337565\n",
      "Loss: 17.993457\n",
      "Loss: 18.178904\n",
      "Loss: 18.586174\n",
      "Loss: 17.994789\n",
      "Loss: 17.582200\n",
      "Loss: 17.410738\n",
      "Loss: 17.542606\n",
      "Loss: 17.369831\n",
      "Loss: 17.550809\n",
      "Loss: 17.314902\n",
      "Loss: 17.160320\n",
      "Loss: 17.193283\n",
      "Loss: 17.268047\n",
      "Loss: 17.128023\n",
      "Loss: 17.203543\n",
      "Loss: 17.023122\n",
      "Loss: 16.845766\n",
      "Loss: 16.850865\n",
      "Loss: 16.867946\n",
      "Loss: 16.747245\n",
      "Loss: 16.731675\n",
      "Loss: 16.689285\n",
      "Loss: 16.584036\n",
      "Loss: 16.622683\n",
      "Loss: 16.699819\n",
      "Loss: 16.688664\n",
      "Loss: 16.744114\n",
      "Loss: 16.623740\n",
      "Loss: 16.422395\n",
      "Loss: 16.471833\n",
      "Loss: 16.701854\n",
      "Loss: 16.388338\n",
      "Loss: 16.194154\n",
      "Loss: 16.208424\n",
      "Loss: 16.318705\n",
      "Loss: 16.212663\n",
      "Loss: 16.334356\n",
      "Loss: 16.143770\n",
      "Loss: 15.897795\n",
      "Loss: 15.966316\n",
      "Loss: 16.119090\n",
      "Loss: 15.868252\n",
      "Loss: 15.708150\n",
      "Loss: 15.737945\n",
      "Loss: 15.768612\n",
      "Loss: 15.796969\n",
      "Loss: 15.998707\n",
      "Loss: 15.799212\n",
      "Loss: 15.576468\n",
      "Loss: 15.627332\n",
      "Loss: 15.790460\n",
      "Loss: 15.510260\n",
      "Loss: 15.332421\n",
      "Loss: 15.381087\n",
      "Loss: 15.525862\n",
      "Loss: 15.395309\n",
      "Loss: 15.408535\n",
      "Loss: 15.300922\n",
      "Loss: 15.151955\n",
      "Loss: 15.242485\n",
      "Loss: 15.464924\n",
      "Loss: 15.208435\n",
      "Loss: 14.967715\n",
      "Loss: 15.034688\n",
      "Loss: 15.177281\n",
      "Loss: 14.899877\n",
      "Loss: 14.798123\n",
      "Loss: 14.786056\n",
      "Loss: 14.784653\n",
      "Loss: 14.830245\n",
      "Loss: 15.029729\n",
      "Loss: 14.884616\n",
      "Loss: 14.665097\n",
      "Loss: 14.754361\n",
      "Loss: 14.932132\n",
      "Loss: 14.614812\n",
      "Loss: 14.428787\n",
      "Loss: 14.444174\n",
      "Loss: 14.443093\n",
      "Loss: 14.363110\n",
      "Loss: 14.380907\n",
      "Loss: 14.376730\n",
      "Loss: 14.297693\n",
      "Loss: 14.381439\n",
      "Loss: 14.498548\n",
      "Loss: 14.312363\n",
      "Loss: 14.122152\n",
      "Loss: 14.144034\n",
      "Loss: 14.153793\n",
      "Loss: 14.009891\n",
      "Loss: 13.906576\n",
      "Loss: 13.924946\n",
      "Loss: 13.922273\n",
      "Loss: 13.930463\n",
      "Loss: 13.946566\n",
      "Loss: 13.899738\n",
      "Loss: 13.808165\n",
      "Loss: 13.826936\n",
      "Loss: 13.817218\n",
      "Loss: 13.714617\n",
      "Loss: 13.597096\n",
      "Loss: 13.608417\n",
      "Loss: 13.570397\n",
      "Loss: 13.535649\n",
      "Loss: 13.474592\n",
      "Loss: 13.471704\n",
      "Loss: 13.419910\n",
      "Loss: 13.429658\n",
      "Loss: 13.392211\n",
      "Loss: 13.364588\n",
      "Loss: 13.291784\n",
      "Loss: 13.292798\n",
      "Loss: 13.233315\n",
      "Loss: 13.211833\n",
      "Loss: 13.141835\n",
      "Loss: 13.136580\n",
      "Loss: 13.069909\n",
      "Loss: 13.067115\n",
      "Loss: 13.005736\n",
      "Loss: 13.002209\n",
      "Loss: 12.939431\n",
      "Loss: 12.941086\n",
      "Loss: 12.878709\n",
      "Loss: 12.877351\n",
      "Loss: 12.813616\n",
      "Loss: 12.813013\n",
      "Loss: 12.745970\n",
      "Loss: 12.745706\n",
      "Loss: 12.678652\n",
      "Loss: 12.679406\n",
      "Loss: 12.612024\n",
      "Loss: 12.614098\n",
      "Loss: 12.546845\n",
      "Loss: 12.550209\n",
      "Loss: 12.483310\n",
      "Loss: 12.487595\n",
      "Loss: 12.420737\n",
      "Loss: 12.425729\n",
      "Loss: 12.358433\n",
      "Loss: 12.363999\n",
      "Loss: 12.296357\n",
      "Loss: 12.302453\n",
      "Loss: 12.234323\n",
      "Loss: 12.240948\n",
      "Loss: 12.172453\n",
      "Loss: 12.179702\n",
      "Loss: 12.110966\n",
      "Loss: 12.118850\n",
      "Loss: 12.050011\n",
      "Loss: 12.058522\n",
      "Loss: 11.989569\n",
      "Loss: 11.998703\n",
      "Loss: 11.929708\n",
      "Loss: 11.939415\n",
      "Loss: 11.870312\n",
      "Loss: 11.880551\n",
      "Loss: 11.811350\n",
      "Loss: 11.822101\n",
      "Loss: 11.752773\n",
      "Loss: 11.763988\n",
      "Loss: 11.694557\n",
      "Loss: 11.706223\n",
      "Loss: 11.636688\n",
      "Loss: 11.648788\n",
      "Loss: 11.579191\n",
      "Loss: 11.591706\n",
      "Loss: 11.522071\n",
      "Loss: 11.534985\n",
      "Loss: 11.465352\n",
      "Loss: 11.478640\n",
      "Loss: 11.409028\n",
      "Loss: 11.422666\n",
      "Loss: 11.353117\n",
      "Loss: 11.367075\n",
      "Loss: 11.297598\n",
      "Loss: 11.311853\n",
      "Loss: 11.242483\n",
      "Loss: 11.257003\n",
      "Loss: 11.187757\n",
      "Loss: 11.202499\n",
      "Loss: 11.133406\n",
      "Loss: 11.148349\n",
      "Loss: 11.079442\n",
      "Loss: 11.094547\n",
      "Loss: 11.025857\n",
      "Loss: 11.041102\n",
      "Loss: 10.972667\n",
      "Loss: 10.988011\n",
      "Loss: 10.919858\n",
      "Loss: 10.935272\n",
      "Loss: 10.867435\n",
      "Loss: 10.882893\n",
      "Loss: 10.815408\n",
      "Loss: 10.830865\n",
      "Loss: 10.763764\n",
      "Loss: 10.779204\n",
      "Loss: 10.712518\n",
      "Loss: 10.727905\n",
      "Loss: 10.661667\n",
      "Loss: 10.676972\n",
      "Loss: 10.611203\n",
      "Loss: 10.626398\n",
      "Loss: 10.561130\n",
      "Loss: 10.576194\n",
      "Loss: 10.511449\n",
      "Loss: 10.526350\n",
      "Loss: 10.462152\n",
      "Loss: 10.476868\n",
      "Loss: 10.413233\n",
      "Loss: 10.427746\n",
      "Loss: 10.364704\n",
      "Loss: 10.378989\n",
      "Loss: 10.316562\n",
      "Loss: 10.330605\n",
      "Loss: 10.268809\n",
      "Loss: 10.282582\n",
      "Loss: 10.221430\n",
      "Loss: 10.234926\n",
      "Loss: 10.174440\n",
      "Loss: 10.187641\n",
      "Loss: 10.127829\n",
      "Loss: 10.140720\n",
      "Loss: 10.081595\n",
      "Loss: 10.094158\n",
      "Loss: 10.035730\n",
      "Loss: 10.047962\n",
      "Loss: 9.990245\n",
      "Loss: 10.002129\n",
      "Loss: 9.945132\n",
      "Loss: 9.956661\n",
      "Loss: 9.900390\n",
      "Loss: 9.911545\n",
      "Loss: 9.856002\n",
      "Loss: 9.866783\n",
      "Loss: 9.811984\n",
      "Loss: 9.822378\n",
      "Loss: 9.768323\n",
      "Loss: 9.778322\n",
      "Loss: 9.725009\n",
      "Loss: 9.734610\n",
      "Loss: 9.682050\n",
      "Loss: 9.691239\n",
      "Loss: 9.639433\n",
      "Loss: 9.648207\n",
      "Loss: 9.597155\n",
      "Loss: 9.605503\n",
      "Loss: 9.555208\n",
      "Loss: 9.563126\n",
      "Loss: 9.513590\n",
      "Loss: 9.521068\n",
      "Loss: 9.472294\n",
      "Loss: 9.479322\n",
      "Loss: 9.431301\n",
      "Loss: 9.437866\n",
      "Loss: 9.390607\n",
      "Loss: 9.396704\n",
      "Loss: 9.350206\n",
      "Loss: 9.355814\n",
      "Loss: 9.310070\n",
      "Loss: 9.315171\n",
      "Loss: 9.270195\n",
      "Loss: 9.274769\n",
      "Loss: 9.230555\n",
      "Loss: 9.234570\n",
      "Loss: 9.191115\n",
      "Loss: 9.194540\n",
      "Loss: 9.151851\n",
      "Loss: 9.154638\n",
      "Loss: 9.112721\n",
      "Loss: 9.114812\n",
      "Loss: 9.073661\n",
      "Loss: 9.074969\n",
      "Loss: 9.034587\n",
      "Loss: 9.035010\n",
      "Loss: 8.995403\n",
      "Loss: 8.994789\n",
      "Loss: 8.955945\n",
      "Loss: 8.954085\n",
      "Loss: 8.915992\n",
      "Loss: 8.912587\n",
      "Loss: 8.875227\n",
      "Loss: 8.869838\n",
      "Loss: 8.833169\n",
      "Loss: 8.825146\n",
      "Loss: 8.789117\n",
      "Loss: 8.777491\n",
      "Loss: 8.742099\n",
      "Loss: 8.725509\n",
      "Loss: 8.691079\n",
      "Loss: 8.668086\n",
      "Loss: 8.636252\n",
      "Loss: 8.607513\n",
      "Loss: 8.582840\n",
      "Loss: 8.556524\n",
      "Loss: 8.540921\n",
      "Loss: 8.525049\n",
      "Loss: 8.507543\n",
      "Loss: 8.493437\n",
      "Loss: 8.472988\n",
      "Loss: 8.461709\n",
      "Loss: 8.453350\n",
      "Loss: 8.436021\n",
      "Loss: 8.435343\n",
      "Loss: 8.434409\n",
      "Loss: 8.422072\n",
      "Loss: 8.415389\n",
      "Loss: 8.394024\n",
      "Loss: 8.373202\n",
      "Loss: 8.386049\n",
      "Loss: 8.388562\n",
      "Loss: 8.381435\n",
      "Loss: 8.343023\n",
      "Loss: 8.302903\n",
      "Loss: 8.309253\n",
      "Loss: 8.283619\n",
      "Loss: 8.254408\n",
      "Loss: 8.228155\n",
      "Loss: 8.222216\n",
      "Loss: 8.220430\n",
      "Loss: 8.187504\n",
      "Loss: 8.156258\n",
      "Loss: 8.156167\n",
      "Loss: 8.148641\n",
      "Loss: 8.141753\n",
      "Loss: 8.114798\n",
      "Loss: 8.104485\n",
      "Loss: 8.112287\n",
      "Loss: 8.077600\n",
      "Loss: 8.043102\n",
      "Loss: 8.045837\n",
      "Loss: 8.037906\n",
      "Loss: 8.031519\n",
      "Loss: 8.003482\n",
      "Loss: 8.000836\n",
      "Loss: 8.014627\n",
      "Loss: 7.969141\n",
      "Loss: 7.934453\n",
      "Loss: 7.940475\n",
      "Loss: 7.916031\n",
      "Loss: 7.896624\n",
      "Loss: 7.882918\n",
      "Loss: 7.890295\n",
      "Loss: 7.902718\n",
      "Loss: 7.857289\n",
      "Loss: 7.838965\n",
      "Loss: 7.854560\n",
      "Loss: 7.808815\n",
      "Loss: 7.776170\n",
      "Loss: 7.778419\n",
      "Loss: 7.765584\n",
      "Loss: 7.761188\n",
      "Loss: 7.741209\n",
      "Loss: 7.753530\n",
      "Loss: 7.768287\n",
      "Loss: 7.714203\n",
      "Loss: 7.698694\n",
      "Loss: 7.714978\n",
      "Loss: 7.661905\n",
      "Loss: 7.634933\n",
      "Loss: 7.639515\n",
      "Loss: 7.619661\n",
      "Loss: 7.610119\n",
      "Loss: 7.598190\n",
      "Loss: 7.614871\n",
      "Loss: 7.620725\n",
      "Loss: 7.573585\n",
      "Loss: 7.573541\n",
      "Loss: 7.589879\n",
      "Loss: 7.526413\n",
      "Loss: 7.507979\n",
      "Loss: 7.518789\n",
      "Loss: 7.479826\n",
      "Loss: 7.460615\n",
      "Loss: 7.462634\n",
      "Loss: 7.463208\n",
      "Loss: 7.457437\n",
      "Loss: 7.436870\n",
      "Loss: 7.458074\n",
      "Loss: 7.459492\n",
      "Loss: 7.403366\n",
      "Loss: 7.403318\n",
      "Loss: 7.417754\n",
      "Loss: 7.353666\n",
      "Loss: 7.339880\n",
      "Loss: 7.353698\n",
      "Loss: 7.314755\n",
      "Loss: 7.299044\n",
      "Loss: 7.305111\n",
      "Loss: 7.304640\n",
      "Loss: 7.290108\n",
      "Loss: 7.278185\n",
      "Loss: 7.303330\n",
      "Loss: 7.289159\n",
      "Loss: 7.244904\n",
      "Loss: 7.258040\n",
      "Loss: 7.263710\n",
      "Loss: 7.197163\n",
      "Loss: 7.193814\n",
      "Loss: 7.209949\n",
      "Loss: 7.154064\n",
      "Loss: 7.143807\n",
      "Loss: 7.163029\n",
      "Loss: 7.134333\n",
      "Loss: 7.119109\n",
      "Loss: 7.131321\n",
      "Loss: 7.135734\n",
      "Loss: 7.108120\n",
      "Loss: 7.103846\n",
      "Loss: 7.130017\n",
      "Loss: 7.096713\n",
      "Loss: 7.064801\n",
      "Loss: 7.088019\n",
      "Loss: 7.072204\n",
      "Loss: 7.015769\n",
      "Loss: 7.024387\n",
      "Loss: 7.029187\n",
      "Loss: 6.968723\n",
      "Loss: 6.967982\n",
      "Loss: 6.987269\n",
      "Loss: 6.935161\n",
      "Loss: 6.930741\n",
      "Loss: 6.959697\n",
      "Loss: 6.917378\n",
      "Loss: 6.907852\n",
      "Loss: 6.942904\n",
      "Loss: 6.908600\n",
      "Loss: 6.890444\n",
      "Loss: 6.928053\n",
      "Loss: 6.904655\n",
      "Loss: 6.873225\n",
      "Loss: 6.908114\n",
      "Loss: 6.903005\n",
      "Loss: 6.854401\n",
      "Loss: 6.874811\n",
      "Loss: 6.886704\n",
      "Loss: 6.827046\n",
      "Loss: 6.823096\n",
      "Loss: 6.836577\n",
      "Loss: 6.786222\n",
      "Loss: 6.766829\n",
      "Loss: 6.770887\n",
      "Loss: 6.740933\n",
      "Loss: 6.721363\n",
      "Loss: 6.719033\n",
      "Loss: 6.699956\n",
      "Loss: 6.692048\n",
      "Loss: 6.685662\n",
      "Loss: 6.670485\n",
      "Loss: 6.683564\n",
      "Loss: 6.671950\n",
      "Loss: 6.661815\n",
      "Loss: 6.697041\n",
      "Loss: 6.672136\n",
      "Loss: 6.655109\n",
      "Loss: 6.708365\n",
      "Loss: 6.667258\n",
      "Loss: 6.620988\n",
      "Loss: 6.676241\n",
      "Loss: 6.631121\n",
      "Loss: 6.581143\n",
      "Loss: 6.603290\n",
      "Loss: 6.581828\n",
      "Loss: 6.554996\n",
      "Loss: 6.562361\n",
      "Loss: 6.586561\n",
      "Loss: 6.558207\n",
      "Loss: 6.570814\n",
      "Loss: 6.650616\n",
      "Loss: 6.582295\n",
      "Loss: 6.580226\n",
      "Loss: 6.666290\n",
      "Loss: 6.558342\n",
      "Loss: 6.485747\n",
      "Loss: 6.485699\n",
      "Loss: 6.442226\n",
      "Loss: 6.412905\n",
      "Loss: 6.407466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 6.375193\n",
      "Loss: 6.388412\n",
      "Loss: 6.388806\n",
      "Loss: 6.355497\n",
      "Loss: 6.391808\n",
      "Loss: 6.370496\n",
      "Loss: 6.333701\n",
      "Loss: 6.386148\n",
      "Loss: 6.358895\n",
      "Loss: 6.326012\n",
      "Loss: 6.416749\n",
      "Loss: 6.368408\n",
      "Loss: 6.325359\n",
      "Loss: 6.458897\n",
      "Loss: 6.368539\n",
      "Loss: 6.289661\n",
      "Loss: 6.371700\n",
      "Loss: 6.301475\n",
      "Loss: 6.227141\n",
      "Loss: 6.218396\n",
      "Loss: 6.188804\n",
      "Loss: 6.182169\n",
      "Loss: 6.189083\n",
      "Loss: 6.151409\n",
      "Loss: 6.175609\n",
      "Loss: 6.176961\n",
      "Loss: 6.129762\n",
      "Loss: 6.182249\n",
      "Loss: 6.172795\n",
      "Loss: 6.115799\n",
      "Loss: 6.211015\n",
      "Loss: 6.183118\n",
      "Loss: 6.111615\n",
      "Loss: 6.262195\n",
      "Loss: 6.190863\n",
      "Loss: 6.088326\n",
      "Loss: 6.214100\n",
      "Loss: 6.142559\n",
      "Loss: 6.045445\n",
      "Loss: 6.067415\n",
      "Loss: 6.031348\n",
      "Loss: 5.990421\n",
      "Loss: 5.992140\n",
      "Loss: 5.974835\n",
      "Loss: 5.951063\n",
      "Loss: 5.952681\n",
      "Loss: 5.940427\n",
      "Loss: 5.921904\n",
      "Loss: 5.921751\n",
      "Loss: 5.913779\n",
      "Loss: 5.889969\n",
      "Loss: 5.889658\n",
      "Loss: 5.896248\n",
      "Loss: 5.870704\n",
      "Loss: 5.856525\n",
      "Loss: 5.881974\n",
      "Loss: 5.914084\n",
      "Loss: 5.841274\n",
      "Loss: 5.923230\n",
      "Loss: 5.990558\n",
      "Loss: 6.046408\n",
      "Loss: 5.936851\n",
      "Loss: 5.889975\n",
      "Loss: 6.402829\n",
      "Loss: 6.209069\n",
      "Loss: 6.470329\n",
      "Loss: 6.259079\n",
      "Loss: 5.869546\n",
      "Loss: 5.917274\n",
      "Loss: 5.771777\n",
      "Loss: 5.872591\n",
      "Loss: 5.855050\n",
      "Loss: 5.722414\n",
      "Loss: 5.751185\n",
      "Loss: 5.702762\n",
      "Loss: 5.693939\n",
      "Loss: 5.701720\n",
      "Loss: 5.662794\n",
      "Loss: 5.671372\n",
      "Loss: 5.664991\n",
      "Loss: 5.637255\n",
      "Loss: 5.633283\n",
      "Loss: 5.629727\n",
      "Loss: 5.612628\n",
      "Loss: 5.604940\n",
      "Loss: 5.600738\n",
      "Loss: 5.587451\n",
      "Loss: 5.577049\n",
      "Loss: 5.573387\n",
      "Loss: 5.564973\n",
      "Loss: 5.550647\n",
      "Loss: 5.544192\n",
      "Loss: 5.542391\n",
      "Loss: 5.532973\n",
      "Loss: 5.514192\n",
      "Loss: 5.511348\n",
      "Loss: 5.519668\n",
      "Loss: 5.512612\n",
      "Loss: 5.473145\n",
      "Loss: 5.485633\n",
      "Loss: 5.524505\n",
      "Loss: 5.570412\n",
      "Loss: 5.456476\n",
      "Loss: 5.629071\n",
      "Loss: 5.629353\n",
      "Loss: 5.595997\n",
      "Loss: 5.703639\n",
      "Loss: 5.475527\n",
      "Loss: 5.470394\n",
      "Loss: 5.420531\n",
      "Loss: 5.539447\n",
      "Loss: 5.422459\n",
      "Loss: 5.395004\n",
      "Loss: 5.390887\n",
      "Loss: 5.487856\n",
      "Loss: 5.391759\n",
      "Loss: 5.352290\n",
      "Loss: 5.345238\n",
      "Loss: 5.341082\n",
      "Loss: 5.354944\n",
      "Loss: 5.433019\n",
      "Loss: 5.347142\n",
      "Loss: 5.552580\n",
      "Loss: 5.390209\n",
      "Loss: 5.302078\n",
      "Loss: 5.327018\n",
      "Loss: 5.308429\n",
      "Loss: 5.313450\n",
      "Loss: 5.261295\n",
      "Loss: 5.444893\n",
      "Loss: 5.324999\n",
      "Loss: 5.255480\n",
      "Loss: 5.350397\n",
      "Loss: 5.252536\n",
      "Loss: 5.211503\n",
      "Loss: 5.206632\n",
      "Loss: 5.334552\n",
      "Loss: 5.229890\n",
      "Loss: 5.227846\n",
      "Loss: 5.166809\n",
      "Loss: 5.325483\n",
      "Loss: 5.238098\n",
      "Loss: 5.171915\n",
      "Loss: 5.272808\n",
      "Loss: 5.167117\n",
      "Loss: 5.143613\n",
      "Loss: 5.113112\n",
      "Loss: 5.278604\n",
      "Loss: 5.160884\n",
      "Loss: 5.112871\n",
      "Loss: 5.146761\n",
      "Loss: 5.111425\n",
      "Loss: 5.131079\n",
      "Loss: 5.069164\n",
      "Loss: 5.269329\n",
      "Loss: 5.144723\n",
      "Loss: 5.071095\n",
      "Loss: 5.317952\n",
      "Loss: 5.134787\n",
      "Loss: 5.025657\n",
      "Loss: 5.150944\n",
      "Loss: 5.084956\n",
      "Loss: 5.011227\n",
      "Loss: 5.223241\n",
      "Loss: 5.097475\n",
      "Loss: 5.025356\n",
      "Loss: 5.185260\n",
      "Loss: 5.000019\n",
      "Loss: 4.950430\n",
      "Loss: 5.041985\n",
      "Loss: 5.006043\n",
      "Loss: 5.117919\n",
      "Loss: 4.991736\n",
      "Loss: 4.957163\n",
      "Loss: 5.180090\n",
      "Loss: 4.955733\n",
      "Loss: 4.989244\n",
      "Loss: 4.930341\n",
      "Loss: 4.866649\n",
      "Loss: 4.926231\n",
      "Loss: 4.887449\n",
      "Loss: 4.843367\n",
      "Loss: 4.905652\n",
      "Loss: 4.858296\n",
      "Loss: 4.808862\n",
      "Loss: 4.830102\n",
      "Loss: 4.852281\n",
      "Loss: 4.837087\n",
      "Loss: 4.927627\n",
      "Loss: 4.819601\n",
      "Loss: 4.802990\n",
      "Loss: 4.903240\n",
      "Loss: 4.782817\n",
      "Loss: 4.719741\n",
      "Loss: 4.747423\n",
      "Loss: 4.773664\n",
      "Loss: 4.712028\n",
      "Loss: 4.757997\n",
      "Loss: 4.868771\n",
      "Loss: 4.808894\n",
      "Loss: 5.050846\n",
      "Loss: 4.977424\n",
      "Loss: 5.154800\n",
      "Loss: 5.312979\n",
      "Loss: 5.000941\n",
      "Loss: 5.177788\n",
      "Loss: 4.897578\n",
      "Loss: 5.057798\n",
      "Loss: 4.856566\n",
      "Loss: 5.006829\n",
      "Loss: 4.798449\n",
      "Loss: 5.003478\n",
      "Loss: 4.823603\n",
      "Loss: 5.061331\n",
      "Loss: 4.872528\n",
      "Loss: 5.150209\n",
      "Loss: 4.927803\n",
      "Loss: 5.277226\n",
      "Loss: 5.173148\n",
      "Loss: 5.449928\n",
      "Loss: 5.233306\n",
      "Loss: 5.207441\n",
      "Loss: 4.886226\n",
      "Loss: 4.780722\n",
      "Loss: 4.686164\n",
      "Loss: 4.725861\n",
      "Loss: 4.590906\n",
      "Loss: 4.628160\n",
      "Loss: 4.647334\n",
      "Loss: 4.693697\n",
      "Loss: 4.566514\n",
      "Loss: 4.665090\n",
      "Loss: 4.609115\n",
      "Loss: 4.658248\n",
      "Loss: 4.527268\n",
      "Loss: 4.663040\n",
      "Loss: 4.614412\n",
      "Loss: 4.694129\n",
      "Loss: 4.545272\n",
      "Loss: 4.709058\n",
      "Loss: 4.647417\n",
      "Loss: 4.820086\n",
      "Loss: 4.619460\n",
      "Loss: 4.749431\n",
      "Loss: 4.682009\n",
      "Loss: 4.815320\n",
      "Loss: 4.578970\n",
      "Loss: 4.591114\n",
      "Loss: 4.528421\n",
      "Loss: 4.620129\n",
      "Loss: 4.477231\n",
      "Loss: 4.524241\n",
      "Loss: 4.486997\n",
      "Loss: 4.583316\n",
      "Loss: 4.437062\n",
      "Loss: 4.512710\n",
      "Loss: 4.480096\n",
      "Loss: 4.591894\n",
      "Loss: 4.438218\n",
      "Loss: 4.514355\n",
      "Loss: 4.477957\n",
      "Loss: 4.590748\n",
      "Loss: 4.424848\n",
      "Loss: 4.480321\n",
      "Loss: 4.448069\n",
      "Loss: 4.543904\n",
      "Loss: 4.387358\n",
      "Loss: 4.429719\n",
      "Loss: 4.405032\n",
      "Loss: 4.495010\n",
      "Loss: 4.351215\n",
      "Loss: 4.399485\n",
      "Loss: 4.378776\n",
      "Loss: 4.471093\n",
      "Loss: 4.328804\n",
      "Loss: 4.380637\n",
      "Loss: 4.361728\n",
      "Loss: 4.453961\n",
      "Loss: 4.310038\n",
      "Loss: 4.356185\n",
      "Loss: 4.339729\n",
      "Loss: 4.427700\n",
      "Loss: 4.285221\n",
      "Loss: 4.324837\n",
      "Loss: 4.312184\n",
      "Loss: 4.396567\n",
      "Loss: 4.257904\n",
      "Loss: 4.295669\n",
      "Loss: 4.286177\n",
      "Loss: 4.369768\n",
      "Loss: 4.233454\n",
      "Loss: 4.271229\n",
      "Loss: 4.263761\n",
      "Loss: 4.347054\n",
      "Loss: 4.211494\n",
      "Loss: 4.247691\n",
      "Loss: 4.242132\n",
      "Loss: 4.323990\n",
      "Loss: 4.189284\n",
      "Loss: 4.222505\n",
      "Loss: 4.219144\n",
      "Loss: 4.299129\n",
      "Loss: 4.165986\n",
      "Loss: 4.196769\n",
      "Loss: 4.195543\n",
      "Loss: 4.274332\n",
      "Loss: 4.142816\n",
      "Loss: 4.172315\n",
      "Loss: 4.172785\n",
      "Loss: 4.251021\n",
      "Loss: 4.120687\n",
      "Loss: 4.149188\n",
      "Loss: 4.150980\n",
      "Loss: 4.228615\n",
      "Loss: 4.099232\n",
      "Loss: 4.126364\n",
      "Loss: 4.129362\n",
      "Loss: 4.206094\n",
      "Loss: 4.077806\n",
      "Loss: 4.103414\n",
      "Loss: 4.107534\n",
      "Loss: 4.183342\n",
      "Loss: 4.056324\n",
      "Loss: 4.080727\n",
      "Loss: 4.085756\n",
      "Loss: 4.160888\n",
      "Loss: 4.035122\n",
      "Loss: 4.058727\n",
      "Loss: 4.064409\n",
      "Loss: 4.139066\n",
      "Loss: 4.014415\n",
      "Loss: 4.037369\n",
      "Loss: 4.043486\n",
      "Loss: 4.117648\n",
      "Loss: 3.994078\n",
      "Loss: 4.016367\n",
      "Loss: 4.022769\n",
      "Loss: 4.096353\n",
      "Loss: 3.973913\n",
      "Loss: 3.995594\n",
      "Loss: 4.002139\n",
      "Loss: 4.075182\n",
      "Loss: 3.953914\n",
      "Loss: 3.975186\n",
      "Loss: 3.981712\n",
      "Loss: 4.054311\n",
      "Loss: 3.934187\n",
      "Loss: 3.955237\n",
      "Loss: 3.961582\n",
      "Loss: 4.033806\n",
      "Loss: 3.914786\n",
      "Loss: 3.935700\n",
      "Loss: 3.941738\n",
      "Loss: 4.013561\n",
      "Loss: 3.895647\n",
      "Loss: 3.916465\n",
      "Loss: 3.922078\n",
      "Loss: 3.993471\n",
      "Loss: 3.876695\n",
      "Loss: 3.897497\n",
      "Loss: 3.902594\n",
      "Loss: 3.973581\n",
      "Loss: 3.857953\n",
      "Loss: 3.878850\n",
      "Loss: 3.883308\n",
      "Loss: 3.953908\n",
      "Loss: 3.839449\n",
      "Loss: 3.860524\n",
      "Loss: 3.864251\n",
      "Loss: 3.934437\n",
      "Loss: 3.821174\n",
      "Loss: 3.842473\n",
      "Loss: 3.845375\n",
      "Loss: 3.915122\n",
      "Loss: 3.803109\n",
      "Loss: 3.824706\n",
      "Loss: 3.826689\n",
      "Loss: 3.895979\n",
      "Loss: 3.785262\n",
      "Loss: 3.807213\n",
      "Loss: 3.808192\n",
      "Loss: 3.876981\n",
      "Loss: 3.767629\n",
      "Loss: 3.789975\n",
      "Loss: 3.789869\n",
      "Loss: 3.858091\n",
      "Loss: 3.750198\n",
      "Loss: 3.773004\n",
      "Loss: 3.771710\n",
      "Loss: 3.839316\n",
      "Loss: 3.732975\n",
      "Loss: 3.756282\n",
      "Loss: 3.753717\n",
      "Loss: 3.820630\n",
      "Loss: 3.715956\n",
      "Loss: 3.739815\n",
      "Loss: 3.735886\n",
      "Loss: 3.802036\n",
      "Loss: 3.699139\n",
      "Loss: 3.723601\n",
      "Loss: 3.718207\n",
      "Loss: 3.783517\n",
      "Loss: 3.682540\n",
      "Loss: 3.707658\n",
      "Loss: 3.700699\n",
      "Loss: 3.765070\n",
      "Loss: 3.666151\n",
      "Loss: 3.691954\n",
      "Loss: 3.683319\n",
      "Loss: 3.746655\n",
      "Loss: 3.649953\n",
      "Loss: 3.676503\n",
      "Loss: 3.666077\n",
      "Loss: 3.728267\n",
      "Loss: 3.633943\n",
      "Loss: 3.661287\n",
      "Loss: 3.648950\n",
      "Loss: 3.709898\n",
      "Loss: 3.618123\n",
      "Loss: 3.646309\n",
      "Loss: 3.631911\n",
      "Loss: 3.691518\n",
      "Loss: 3.602461\n",
      "Loss: 3.631562\n",
      "Loss: 3.614955\n",
      "Loss: 3.673160\n",
      "Loss: 3.587003\n",
      "Loss: 3.617083\n",
      "Loss: 3.598079\n",
      "Loss: 3.654778\n",
      "Loss: 3.571704\n",
      "Loss: 3.602817\n",
      "Loss: 3.581230\n",
      "Loss: 3.636362\n",
      "Loss: 3.556584\n",
      "Loss: 3.588803\n",
      "Loss: 3.564388\n",
      "Loss: 3.617898\n",
      "Loss: 3.541603\n",
      "Loss: 3.575009\n",
      "Loss: 3.547536\n",
      "Loss: 3.599406\n",
      "Loss: 3.526790\n",
      "Loss: 3.561456\n",
      "Loss: 3.530662\n",
      "Loss: 3.580897\n",
      "Loss: 3.512123\n",
      "Loss: 3.548131\n",
      "Loss: 3.513787\n",
      "Loss: 3.562437\n",
      "Loss: 3.497598\n",
      "Loss: 3.535007\n",
      "Loss: 3.496962\n",
      "Loss: 3.544140\n",
      "Loss: 3.483196\n",
      "Loss: 3.522029\n",
      "Loss: 3.480291\n",
      "Loss: 3.526148\n",
      "Loss: 3.468839\n",
      "Loss: 3.509046\n",
      "Loss: 3.463923\n",
      "Loss: 3.508674\n",
      "Loss: 3.454430\n",
      "Loss: 3.495848\n",
      "Loss: 3.447961\n",
      "Loss: 3.491882\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    Loss = np.zeros(ae_iters)\n",
    "    for i in range(ae_iters):\n",
    "        Ll = 0\n",
    "        for j in range(cell_len):\n",
    "            x, t, a = generate_batches(Data, Time, Assignments, j)\n",
    "            _, L = sess.run([optimizer, loss_ae], feed_dict = {lstm_ae.input: x, lstm_ae.time: t})\n",
    "            Ll += L\n",
    "        Loss[i] = Ll / cell_len\n",
    "        print('Loss: %f' %(Loss[i]))\n",
    "\n",
    "    assign_truth = []\n",
    "    data_reps = []\n",
    "    for c in range(cell_len):\n",
    "        data = np.transpose(Data[0][c])\n",
    "        time = np.transpose(Time[0][c])\n",
    "        assign = np.transpose(Assignments[0][c])\n",
    "        reps, cells = sess.run(lstm_ae.get_representation(), feed_dict = {lstm_ae.input: data, lstm_ae.time: time})\n",
    "        if c == 0:\n",
    "            data_reps = reps\n",
    "            assign_truth = assign\n",
    "        else:\n",
    "            data_reps = np.concatenate((data_reps, reps))\n",
    "            assign_truth = np.concatenate((assign_truth, assign))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'TLSTM')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "######## Clustering ##########################\n",
    "kmeans = KMeans(n_clusters = 4, random_state = 0, init = 'k-means++').fit(data_reps)\n",
    "centroid_values = kmeans.cluster_centers_\n",
    "\n",
    "#plt.figure(1)\n",
    "plt.scatter(data_reps[:, 0], data_reps[:, 1])\n",
    "plt.plot(centroid_values[:, 0], centroid_values[:, 1], 'kx', markersize = 35, alpha = 0.5)\n",
    "#, c = assign_truth, s = 50, I had to remove this code from the above line because it does not work in matplotlib 2.2.3\n",
    "plt.title('TLSTM')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(assign_truth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py2_ML",
   "language": "python",
   "name": "py2_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
