{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `jupyter notebook` for the `T-LSTM.py` example\n",
    "\n",
    "Modified from the [`T-LSTM`](https://github.com/illidanlab/T-LSTM/blob/master/main_AE.py) repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required packages. Note that this notebook uses the autoencode example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A toy example for clustering with 2-layer TLSTM auto-encoder\n",
    "# Inci M. Baytas, 2017\n",
    "# How to run: Directly run the main file: python main_AE.py\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import h5py\n",
    "\n",
    "from T_LSTM_AE import T_LSTM_AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a quick look at the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'#refs#', u'Assign', u'Data', u'Time']\n",
      "<HDF5 group \"/#refs#\" (16 members)>\n",
      "<HDF5 dataset \"Assign\": shape (1, 5), type \"|O\">\n",
      "<HDF5 dataset \"Data\": shape (1, 5), type \"|O\">\n",
      "<HDF5 dataset \"Time\": shape (1, 5), type \"|O\">\n"
     ]
    }
   ],
   "source": [
    "cluster_data = h5py.File('../data/Clustering_Data_1D.mat')\n",
    "print(list(cluster_data.keys()))\n",
    "\n",
    "for item in cluster_data.keys():\n",
    "    print(cluster_data[item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A synthetic data\n",
    "\n",
    "Data = []\n",
    "Time = []\n",
    "Assignments = []\n",
    "Target = []\n",
    "with h5py.File(\"../data/Clustering_Data_1D.mat\") as f:#\n",
    "    for column in f['Data']:\n",
    "        row_data = []\n",
    "        for row_number in range(len(column)):\n",
    "            row_data.append(f[column[row_number]][:])\n",
    "    Data.append(row_data)\n",
    "    for column in f['Time']:\n",
    "        row_data = []\n",
    "        for row_number in range(len(column)):\n",
    "            row_data.append(f[column[row_number]][:])\n",
    "    Time.append(row_data)\n",
    "    for column in f['Assign']:\n",
    "        row_data = []\n",
    "        for row_number in range(len(column)):\n",
    "            row_data.append(f[column[row_number]][:])\n",
    "    Assignments.append(row_data)\n",
    "\n",
    "cell_len = len(Data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Investigate the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(type(Data)) # The data object is a list\n",
    "print(len(Data))\n",
    "#print(Data) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to generate batches of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batches(data, time, assign, index):\n",
    "    batch_data = np.transpose(data[0][index])\n",
    "    batch_time = np.transpose(time[0][index])\n",
    "    batch_assign = np.transpose(assign[0][index])\n",
    "    return batch_data, batch_time, batch_assign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set learning parameters\n",
    "learning_rate = 1e-3\n",
    "ae_iters = 2000 #Number of iterations (epochs)\n",
    "\n",
    "# set network parameters\n",
    "input_dim = np.size(Data[0][0], 0)\n",
    "hidden_dim = 8\n",
    "hidden_dim2 = 2\n",
    "hidden_dim3 = 8\n",
    "output_dim = hidden_dim\n",
    "output_dim2 = hidden_dim2\n",
    "output_dim3 = input_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model, set the loss function, optimizer, and initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_ae = T_LSTM_AE(input_dim, output_dim, output_dim2, output_dim3, hidden_dim, hidden_dim2, hidden_dim3)\n",
    "\n",
    "loss_ae = lstm_ae.get_reconstruction_loss()\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(loss_ae)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 326.614603\n",
      "Loss: 326.311670\n",
      "Loss: 326.008923\n",
      "Loss: 325.704449\n",
      "Loss: 325.396164\n",
      "Loss: 325.081308\n",
      "Loss: 324.756427\n",
      "Loss: 324.417303\n",
      "Loss: 324.058899\n",
      "Loss: 323.675363\n",
      "Loss: 323.260019\n",
      "Loss: 322.804779\n",
      "Loss: 322.298993\n",
      "Loss: 321.729022\n",
      "Loss: 321.070102\n",
      "Loss: 320.261560\n",
      "Loss: 319.103720\n",
      "Loss: 316.927057\n",
      "Loss: 314.692477\n",
      "Loss: 313.329672\n",
      "Loss: 312.021729\n",
      "Loss: 310.679477\n",
      "Loss: 309.285568\n",
      "Loss: 307.835321\n",
      "Loss: 306.330542\n",
      "Loss: 304.776852\n",
      "Loss: 303.181824\n",
      "Loss: 301.554025\n",
      "Loss: 299.903528\n",
      "Loss: 298.237561\n",
      "Loss: 296.562381\n",
      "Loss: 294.882358\n",
      "Loss: 293.201443\n",
      "Loss: 291.522052\n",
      "Loss: 289.846063\n",
      "Loss: 288.174429\n",
      "Loss: 286.507492\n",
      "Loss: 284.844913\n",
      "Loss: 283.185712\n",
      "Loss: 281.528326\n",
      "Loss: 279.870679\n",
      "Loss: 278.210446\n",
      "Loss: 276.546042\n",
      "Loss: 274.878598\n",
      "Loss: 273.214362\n",
      "Loss: 271.562683\n",
      "Loss: 269.943115\n",
      "Loss: 268.358188\n",
      "Loss: 266.811038\n",
      "Loss: 265.296609\n",
      "Loss: 263.814856\n",
      "Loss: 262.363574\n",
      "Loss: 260.936920\n",
      "Loss: 259.533423\n",
      "Loss: 258.179001\n",
      "Loss: 256.838480\n",
      "Loss: 255.510483\n",
      "Loss: 254.202826\n",
      "Loss: 252.922604\n",
      "Loss: 251.657153\n",
      "Loss: 250.401434\n",
      "Loss: 249.111893\n",
      "Loss: 247.900500\n",
      "Loss: 246.694171\n",
      "Loss: 245.403561\n",
      "Loss: 244.244156\n",
      "Loss: 243.007352\n",
      "Loss: 241.837204\n",
      "Loss: 240.712540\n",
      "Loss: 239.536569\n",
      "Loss: 238.456085\n",
      "Loss: 237.325674\n",
      "Loss: 236.229630\n",
      "Loss: 235.164532\n",
      "Loss: 234.087256\n",
      "Loss: 233.038138\n",
      "Loss: 231.995792\n",
      "Loss: 230.958859\n",
      "Loss: 229.941473\n",
      "Loss: 228.927594\n",
      "Loss: 227.923398\n",
      "Loss: 226.932169\n",
      "Loss: 225.946448\n",
      "Loss: 224.970950\n",
      "Loss: 224.004636\n",
      "Loss: 223.045889\n",
      "Loss: 222.097537\n",
      "Loss: 221.157574\n",
      "Loss: 220.226013\n",
      "Loss: 219.303619\n",
      "Loss: 218.389136\n",
      "Loss: 217.483008\n",
      "Loss: 216.584247\n",
      "Loss: 215.692798\n",
      "Loss: 214.808682\n",
      "Loss: 213.931635\n",
      "Loss: 213.061923\n",
      "Loss: 212.199661\n",
      "Loss: 211.345807\n",
      "Loss: 210.498929\n",
      "Loss: 209.658340\n",
      "Loss: 208.824664\n",
      "Loss: 207.997711\n",
      "Loss: 207.177023\n",
      "Loss: 206.362784\n",
      "Loss: 205.554736\n",
      "Loss: 204.752670\n",
      "Loss: 203.957288\n",
      "Loss: 203.168329\n",
      "Loss: 202.384256\n",
      "Loss: 201.606671\n",
      "Loss: 200.835175\n",
      "Loss: 200.069220\n",
      "Loss: 199.309705\n",
      "Loss: 198.555161\n",
      "Loss: 197.806441\n",
      "Loss: 197.064352\n",
      "Loss: 196.326167\n",
      "Loss: 195.594463\n",
      "Loss: 194.868596\n",
      "Loss: 194.147217\n",
      "Loss: 193.435997\n",
      "Loss: 192.727304\n",
      "Loss: 192.014281\n",
      "Loss: 191.333238\n",
      "Loss: 190.680679\n",
      "Loss: 190.004810\n",
      "Loss: 189.283676\n",
      "Loss: 188.604382\n",
      "Loss: 187.955557\n",
      "Loss: 187.250615\n",
      "Loss: 186.580208\n",
      "Loss: 185.912094\n",
      "Loss: 185.287413\n",
      "Loss: 184.620961\n",
      "Loss: 183.980469\n",
      "Loss: 183.328917\n",
      "Loss: 182.714168\n",
      "Loss: 182.084134\n",
      "Loss: 181.472617\n",
      "Loss: 180.831978\n",
      "Loss: 180.239577\n",
      "Loss: 179.614966\n",
      "Loss: 179.033614\n",
      "Loss: 178.377101\n",
      "Loss: 177.787497\n",
      "Loss: 177.169778\n",
      "Loss: 176.582065\n",
      "Loss: 175.985519\n",
      "Loss: 175.403192\n",
      "Loss: 174.819434\n",
      "Loss: 174.244218\n",
      "Loss: 173.669507\n",
      "Loss: 173.100719\n",
      "Loss: 172.533389\n",
      "Loss: 171.970494\n",
      "Loss: 171.411047\n",
      "Loss: 170.854836\n",
      "Loss: 170.302841\n",
      "Loss: 169.753981\n",
      "Loss: 169.208772\n",
      "Loss: 168.668022\n",
      "Loss: 168.130797\n",
      "Loss: 167.596846\n",
      "Loss: 167.067389\n",
      "Loss: 166.542130\n",
      "Loss: 166.019331\n",
      "Loss: 165.499409\n",
      "Loss: 164.985652\n",
      "Loss: 164.473578\n",
      "Loss: 163.962607\n",
      "Loss: 163.471184\n",
      "Loss: 162.970146\n",
      "Loss: 162.479126\n",
      "Loss: 161.990164\n",
      "Loss: 161.533835\n",
      "Loss: 161.069698\n",
      "Loss: 160.574059\n",
      "Loss: 160.409952\n",
      "Loss: 159.789226\n",
      "Loss: 159.201550\n",
      "Loss: 158.661703\n",
      "Loss: 158.233582\n",
      "Loss: 157.713510\n",
      "Loss: 157.282819\n",
      "Loss: 156.788884\n",
      "Loss: 156.365924\n",
      "Loss: 155.888339\n",
      "Loss: 155.429919\n",
      "Loss: 154.970723\n",
      "Loss: 154.524606\n",
      "Loss: 154.073546\n",
      "Loss: 153.628627\n",
      "Loss: 153.189580\n",
      "Loss: 152.752309\n",
      "Loss: 152.319519\n",
      "Loss: 151.888023\n",
      "Loss: 151.460309\n",
      "Loss: 151.033382\n",
      "Loss: 150.609885\n",
      "Loss: 150.186951\n",
      "Loss: 149.765742\n",
      "Loss: 149.345445\n",
      "Loss: 148.926942\n",
      "Loss: 148.510851\n",
      "Loss: 148.097101\n",
      "Loss: 147.685683\n",
      "Loss: 147.275046\n",
      "Loss: 146.870361\n",
      "Loss: 146.464662\n",
      "Loss: 146.064880\n",
      "Loss: 145.661475\n",
      "Loss: 145.269377\n",
      "Loss: 144.870178\n",
      "Loss: 144.488255\n",
      "Loss: 144.091083\n",
      "Loss: 143.733559\n",
      "Loss: 143.324927\n",
      "Loss: 143.051825\n",
      "Loss: 142.643263\n",
      "Loss: 142.310617\n",
      "Loss: 141.807188\n",
      "Loss: 141.420059\n",
      "Loss: 141.024332\n",
      "Loss: 140.646130\n",
      "Loss: 140.292604\n",
      "Loss: 139.890005\n",
      "Loss: 139.523055\n",
      "Loss: 139.152325\n",
      "Loss: 138.781375\n",
      "Loss: 138.414474\n",
      "Loss: 138.051593\n",
      "Loss: 137.689940\n",
      "Loss: 137.331943\n",
      "Loss: 136.988596\n",
      "Loss: 136.635634\n",
      "Loss: 136.293863\n",
      "Loss: 135.915785\n",
      "Loss: 135.595181\n",
      "Loss: 135.253580\n",
      "Loss: 134.900278\n",
      "Loss: 134.531175\n",
      "Loss: 134.159644\n",
      "Loss: 133.827875\n",
      "Loss: 133.440628\n",
      "Loss: 133.102168\n",
      "Loss: 132.762839\n",
      "Loss: 132.408040\n",
      "Loss: 132.062157\n",
      "Loss: 131.727069\n",
      "Loss: 131.393004\n",
      "Loss: 131.059019\n",
      "Loss: 130.715776\n",
      "Loss: 130.376001\n",
      "Loss: 130.046671\n",
      "Loss: 129.724098\n",
      "Loss: 129.395221\n",
      "Loss: 129.048346\n",
      "Loss: 128.711359\n",
      "Loss: 128.410381\n",
      "Loss: 128.100912\n",
      "Loss: 127.859837\n",
      "Loss: 127.497079\n",
      "Loss: 127.102429\n",
      "Loss: 126.817525\n",
      "Loss: 126.496350\n",
      "Loss: 126.151295\n",
      "Loss: 125.810300\n",
      "Loss: 125.503152\n",
      "Loss: 125.188405\n",
      "Loss: 124.876880\n",
      "Loss: 124.551089\n",
      "Loss: 124.259998\n",
      "Loss: 123.965837\n",
      "Loss: 123.700087\n",
      "Loss: 123.544046\n",
      "Loss: 123.099742\n",
      "Loss: 122.786143\n",
      "Loss: 122.509816\n",
      "Loss: 122.160826\n",
      "Loss: 121.811304\n",
      "Loss: 121.527676\n",
      "Loss: 121.203525\n",
      "Loss: 120.892271\n",
      "Loss: 120.610873\n",
      "Loss: 120.295366\n",
      "Loss: 119.980916\n",
      "Loss: 119.681779\n",
      "Loss: 119.396410\n",
      "Loss: 119.102821\n",
      "Loss: 118.802318\n",
      "Loss: 118.505493\n",
      "Loss: 118.204980\n",
      "Loss: 117.916528\n",
      "Loss: 117.622798\n",
      "Loss: 117.344270\n",
      "Loss: 117.099748\n",
      "Loss: 116.847125\n",
      "Loss: 116.821745\n",
      "Loss: 116.220215\n",
      "Loss: 116.000473\n",
      "Loss: 115.656854\n",
      "Loss: 115.339922\n",
      "Loss: 114.976790\n",
      "Loss: 114.694504\n",
      "Loss: 114.378857\n",
      "Loss: 114.077968\n",
      "Loss: 113.751501\n",
      "Loss: 113.474030\n",
      "Loss: 113.189664\n",
      "Loss: 113.020786\n",
      "Loss: 112.659175\n",
      "Loss: 112.467928\n",
      "Loss: 112.064964\n",
      "Loss: 111.782440\n",
      "Loss: 111.466924\n",
      "Loss: 111.141788\n",
      "Loss: 110.883001\n",
      "Loss: 110.573416\n",
      "Loss: 110.277381\n",
      "Loss: 110.008305\n",
      "Loss: 109.753415\n",
      "Loss: 109.482705\n",
      "Loss: 109.174823\n",
      "Loss: 108.904691\n",
      "Loss: 108.643623\n",
      "Loss: 108.429807\n",
      "Loss: 108.164927\n",
      "Loss: 107.858574\n",
      "Loss: 107.656052\n",
      "Loss: 107.340011\n",
      "Loss: 107.167683\n",
      "Loss: 106.809548\n",
      "Loss: 106.594286\n",
      "Loss: 106.295369\n",
      "Loss: 106.080315\n",
      "Loss: 105.760843\n",
      "Loss: 105.487403\n",
      "Loss: 105.231483\n",
      "Loss: 105.003448\n",
      "Loss: 104.705651\n",
      "Loss: 104.434929\n",
      "Loss: 104.182666\n",
      "Loss: 103.969245\n",
      "Loss: 103.674358\n",
      "Loss: 103.407061\n",
      "Loss: 103.159314\n",
      "Loss: 102.935667\n",
      "Loss: 102.657097\n",
      "Loss: 102.378325\n",
      "Loss: 102.144668\n",
      "Loss: 101.902754\n",
      "Loss: 101.645945\n",
      "Loss: 101.353771\n",
      "Loss: 101.132344\n",
      "Loss: 100.872631\n",
      "Loss: 100.642009\n",
      "Loss: 100.336795\n",
      "Loss: 100.121326\n",
      "Loss: 99.853450\n",
      "Loss: 99.641722\n",
      "Loss: 99.351594\n",
      "Loss: 99.103751\n",
      "Loss: 98.874011\n",
      "Loss: 98.619632\n",
      "Loss: 98.411826\n",
      "Loss: 98.136726\n",
      "Loss: 97.890955\n",
      "Loss: 97.680782\n",
      "Loss: 97.411298\n",
      "Loss: 97.223633\n",
      "Loss: 96.976779\n",
      "Loss: 96.707898\n",
      "Loss: 96.543391\n",
      "Loss: 96.243875\n",
      "Loss: 96.018534\n",
      "Loss: 95.775673\n",
      "Loss: 95.490547\n",
      "Loss: 95.307703\n",
      "Loss: 95.043917\n",
      "Loss: 94.805383\n",
      "Loss: 94.576567\n",
      "Loss: 94.301722\n",
      "Loss: 94.091144\n",
      "Loss: 93.858515\n",
      "Loss: 93.619256\n",
      "Loss: 93.413252\n",
      "Loss: 93.150240\n",
      "Loss: 92.928688\n",
      "Loss: 92.725062\n",
      "Loss: 92.464836\n",
      "Loss: 92.277775\n",
      "Loss: 92.036723\n",
      "Loss: 91.791418\n",
      "Loss: 91.626153\n",
      "Loss: 91.347724\n",
      "Loss: 91.126315\n",
      "Loss: 90.914129\n",
      "Loss: 90.642619\n",
      "Loss: 90.471527\n",
      "Loss: 90.242219\n",
      "Loss: 89.978024\n",
      "Loss: 89.778332\n",
      "Loss: 89.508669\n",
      "Loss: 89.304202\n",
      "Loss: 89.102384\n",
      "Loss: 88.846861\n",
      "Loss: 88.647289\n",
      "Loss: 88.399133\n",
      "Loss: 88.172020\n",
      "Loss: 87.977700\n",
      "Loss: 87.738268\n",
      "Loss: 87.536882\n",
      "Loss: 87.320602\n",
      "Loss: 87.079095\n",
      "Loss: 86.883529\n",
      "Loss: 86.675653\n",
      "Loss: 86.443070\n",
      "Loss: 86.260511\n",
      "Loss: 86.031658\n",
      "Loss: 85.811049\n",
      "Loss: 85.644698\n",
      "Loss: 85.398882\n",
      "Loss: 85.177045\n",
      "Loss: 84.987084\n",
      "Loss: 84.741116\n",
      "Loss: 84.548030\n",
      "Loss: 84.375934\n",
      "Loss: 84.104449\n",
      "Loss: 83.907316\n",
      "Loss: 83.685009\n",
      "Loss: 83.458389\n",
      "Loss: 83.277385\n",
      "Loss: 83.062180\n",
      "Loss: 82.843488\n",
      "Loss: 82.645294\n",
      "Loss: 82.421707\n",
      "Loss: 82.214982\n",
      "Loss: 82.029837\n",
      "Loss: 81.817866\n",
      "Loss: 81.617289\n",
      "Loss: 81.420602\n",
      "Loss: 81.201356\n",
      "Loss: 81.002498\n",
      "Loss: 80.823720\n",
      "Loss: 80.618448\n",
      "Loss: 80.423059\n",
      "Loss: 80.239886\n",
      "Loss: 80.018765\n",
      "Loss: 79.822998\n",
      "Loss: 79.663414\n",
      "Loss: 79.465074\n",
      "Loss: 79.249847\n",
      "Loss: 79.085903\n",
      "Loss: 78.860420\n",
      "Loss: 78.652028\n",
      "Loss: 78.510575\n",
      "Loss: 78.303741\n",
      "Loss: 78.063771\n",
      "Loss: 77.887114\n",
      "Loss: 77.656760\n",
      "Loss: 77.451107\n",
      "Loss: 77.282582\n",
      "Loss: 77.074332\n",
      "Loss: 76.873315\n",
      "Loss: 76.680217\n",
      "Loss: 76.470569\n",
      "Loss: 76.276001\n",
      "Loss: 76.091299\n",
      "Loss: 75.898887\n",
      "Loss: 75.708882\n",
      "Loss: 75.516975\n",
      "Loss: 75.320982\n",
      "Loss: 75.132485\n",
      "Loss: 74.950955\n",
      "Loss: 74.768404\n",
      "Loss: 74.585423\n",
      "Loss: 74.401247\n",
      "Loss: 74.213893\n",
      "Loss: 74.029478\n",
      "Loss: 73.851240\n",
      "Loss: 73.674645\n",
      "Loss: 73.497408\n",
      "Loss: 73.319730\n",
      "Loss: 73.138676\n",
      "Loss: 72.955389\n",
      "Loss: 72.776257\n",
      "Loss: 72.602443\n",
      "Loss: 72.429993\n",
      "Loss: 72.258315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 72.087283\n",
      "Loss: 71.910670\n",
      "Loss: 71.728432\n",
      "Loss: 71.551403\n",
      "Loss: 71.383017\n",
      "Loss: 71.216467\n",
      "Loss: 71.051176\n",
      "Loss: 70.895428\n",
      "Loss: 70.735477\n",
      "Loss: 70.552137\n",
      "Loss: 70.372292\n",
      "Loss: 70.219707\n",
      "Loss: 70.072591\n",
      "Loss: 69.897095\n",
      "Loss: 69.749706\n",
      "Loss: 69.618581\n",
      "Loss: 69.417273\n",
      "Loss: 69.220690\n",
      "Loss: 69.103007\n",
      "Loss: 68.933291\n",
      "Loss: 68.714128\n",
      "Loss: 68.558323\n",
      "Loss: 68.367696\n",
      "Loss: 68.182939\n",
      "Loss: 68.020085\n",
      "Loss: 67.854872\n",
      "Loss: 67.694360\n",
      "Loss: 67.534912\n",
      "Loss: 67.370480\n",
      "Loss: 67.205244\n",
      "Loss: 67.042530\n",
      "Loss: 66.881931\n",
      "Loss: 66.723414\n",
      "Loss: 66.567062\n",
      "Loss: 66.410842\n",
      "Loss: 66.252103\n",
      "Loss: 66.091258\n",
      "Loss: 65.930984\n",
      "Loss: 65.772130\n",
      "Loss: 65.615160\n",
      "Loss: 65.462369\n",
      "Loss: 65.313212\n",
      "Loss: 65.162182\n",
      "Loss: 65.006326\n",
      "Loss: 64.848628\n",
      "Loss: 64.691844\n",
      "Loss: 64.534512\n",
      "Loss: 64.378618\n",
      "Loss: 64.235258\n",
      "Loss: 64.100757\n",
      "Loss: 63.957482\n",
      "Loss: 63.805440\n",
      "Loss: 63.655586\n",
      "Loss: 63.510699\n",
      "Loss: 63.356251\n",
      "Loss: 63.188557\n",
      "Loss: 63.056923\n",
      "Loss: 62.936047\n",
      "Loss: 62.787950\n",
      "Loss: 62.634410\n",
      "Loss: 62.486076\n",
      "Loss: 62.355737\n",
      "Loss: 62.170027\n",
      "Loss: 62.006613\n",
      "Loss: 61.874979\n",
      "Loss: 61.726338\n",
      "Loss: 61.567085\n",
      "Loss: 61.412234\n",
      "Loss: 61.262675\n",
      "Loss: 61.110873\n",
      "Loss: 60.970159\n",
      "Loss: 60.833544\n",
      "Loss: 60.690510\n",
      "Loss: 60.543469\n",
      "Loss: 60.395969\n",
      "Loss: 60.249455\n",
      "Loss: 60.104314\n",
      "Loss: 59.964702\n",
      "Loss: 59.829299\n",
      "Loss: 59.691968\n",
      "Loss: 59.551530\n",
      "Loss: 59.410532\n",
      "Loss: 59.268643\n",
      "Loss: 59.124473\n",
      "Loss: 58.981082\n",
      "Loss: 58.845024\n",
      "Loss: 58.715132\n",
      "Loss: 58.582192\n",
      "Loss: 58.443534\n",
      "Loss: 58.307518\n",
      "Loss: 58.174302\n",
      "Loss: 58.035030\n",
      "Loss: 57.888570\n",
      "Loss: 57.747886\n",
      "Loss: 57.625853\n",
      "Loss: 57.512867\n",
      "Loss: 57.383576\n",
      "Loss: 57.238088\n",
      "Loss: 57.110839\n",
      "Loss: 56.987523\n",
      "Loss: 56.848235\n",
      "Loss: 56.697557\n",
      "Loss: 56.563076\n",
      "Loss: 56.461060\n",
      "Loss: 56.351590\n",
      "Loss: 56.205482\n",
      "Loss: 56.074658\n",
      "Loss: 55.940084\n",
      "Loss: 55.806374\n",
      "Loss: 55.660026\n",
      "Loss: 55.513136\n",
      "Loss: 55.395087\n",
      "Loss: 55.267439\n",
      "Loss: 55.132133\n",
      "Loss: 54.990717\n",
      "Loss: 54.850102\n",
      "Loss: 54.714021\n",
      "Loss: 54.581820\n",
      "Loss: 54.463771\n",
      "Loss: 54.350802\n",
      "Loss: 54.231767\n",
      "Loss: 54.111379\n",
      "Loss: 53.977994\n",
      "Loss: 53.834684\n",
      "Loss: 53.695816\n",
      "Loss: 53.566045\n",
      "Loss: 53.455125\n",
      "Loss: 53.352933\n",
      "Loss: 53.244088\n",
      "Loss: 53.136347\n",
      "Loss: 53.002077\n",
      "Loss: 52.852602\n",
      "Loss: 52.716603\n",
      "Loss: 52.581911\n",
      "Loss: 52.474454\n",
      "Loss: 52.376821\n",
      "Loss: 52.269685\n",
      "Loss: 52.141285\n",
      "Loss: 51.988936\n",
      "Loss: 51.851796\n",
      "Loss: 51.718330\n",
      "Loss: 51.602113\n",
      "Loss: 51.506356\n",
      "Loss: 51.404280\n",
      "Loss: 51.284217\n",
      "Loss: 51.139173\n",
      "Loss: 50.997565\n",
      "Loss: 50.867412\n",
      "Loss: 50.749979\n",
      "Loss: 50.653086\n",
      "Loss: 50.558912\n",
      "Loss: 50.453743\n",
      "Loss: 50.321747\n",
      "Loss: 50.175307\n",
      "Loss: 50.041222\n",
      "Loss: 49.919333\n",
      "Loss: 49.818792\n",
      "Loss: 49.730619\n",
      "Loss: 49.636782\n",
      "Loss: 49.519447\n",
      "Loss: 49.372530\n",
      "Loss: 49.232460\n",
      "Loss: 49.107141\n",
      "Loss: 49.001152\n",
      "Loss: 48.915268\n",
      "Loss: 48.826377\n",
      "Loss: 48.716827\n",
      "Loss: 48.574214\n",
      "Loss: 48.430917\n",
      "Loss: 48.304837\n",
      "Loss: 48.197065\n",
      "Loss: 48.111201\n",
      "Loss: 48.024039\n",
      "Loss: 47.918270\n",
      "Loss: 47.781537\n",
      "Loss: 47.638155\n",
      "Loss: 47.512123\n",
      "Loss: 47.405416\n",
      "Loss: 47.319353\n",
      "Loss: 47.233824\n",
      "Loss: 47.132587\n",
      "Loss: 47.001595\n",
      "Loss: 46.858712\n",
      "Loss: 46.732380\n",
      "Loss: 46.626863\n",
      "Loss: 46.540863\n",
      "Loss: 46.456758\n",
      "Loss: 46.359216\n",
      "Loss: 46.232209\n",
      "Loss: 46.090340\n",
      "Loss: 45.964531\n",
      "Loss: 45.860875\n",
      "Loss: 45.775602\n",
      "Loss: 45.692310\n",
      "Loss: 45.596170\n",
      "Loss: 45.470431\n",
      "Loss: 45.330507\n",
      "Loss: 45.207260\n",
      "Loss: 45.106911\n",
      "Loss: 45.022941\n",
      "Loss: 44.940158\n",
      "Loss: 44.843420\n",
      "Loss: 44.716639\n",
      "Loss: 44.579229\n",
      "Loss: 44.460445\n",
      "Loss: 44.364438\n",
      "Loss: 44.282185\n",
      "Loss: 44.200409\n",
      "Loss: 44.101869\n",
      "Loss: 43.972153\n",
      "Loss: 43.837340\n",
      "Loss: 43.724144\n",
      "Loss: 43.632817\n",
      "Loss: 43.553131\n",
      "Loss: 43.473380\n",
      "Loss: 43.370923\n",
      "Loss: 43.236129\n",
      "Loss: 43.104692\n",
      "Loss: 42.998059\n",
      "Loss: 42.911798\n",
      "Loss: 42.836465\n",
      "Loss: 42.758189\n",
      "Loss: 42.646653\n",
      "Loss: 42.505988\n",
      "Loss: 42.380949\n",
      "Loss: 42.282050\n",
      "Loss: 42.202242\n",
      "Loss: 42.133066\n",
      "Loss: 42.050508\n",
      "Loss: 41.922701\n",
      "Loss: 41.780937\n",
      "Loss: 41.666556\n",
      "Loss: 41.576812\n",
      "Loss: 41.506534\n",
      "Loss: 41.441331\n",
      "Loss: 41.340660\n",
      "Loss: 41.195392\n",
      "Loss: 41.064138\n",
      "Loss: 40.962924\n",
      "Loss: 40.886094\n",
      "Loss: 40.827587\n",
      "Loss: 40.750549\n",
      "Loss: 40.616538\n",
      "Loss: 40.471716\n",
      "Loss: 40.359796\n",
      "Loss: 40.275370\n",
      "Loss: 40.218740\n",
      "Loss: 40.156028\n",
      "Loss: 40.035658\n",
      "Loss: 39.884745\n",
      "Loss: 39.764586\n",
      "Loss: 39.675672\n",
      "Loss: 39.620152\n",
      "Loss: 39.564911\n",
      "Loss: 39.450985\n",
      "Loss: 39.299068\n",
      "Loss: 39.175370\n",
      "Loss: 39.086180\n",
      "Loss: 39.034598\n",
      "Loss: 38.981532\n",
      "Loss: 38.865610\n",
      "Loss: 38.713815\n",
      "Loss: 38.592132\n",
      "Loss: 38.506837\n",
      "Loss: 38.462229\n",
      "Loss: 38.406137\n",
      "Loss: 38.282130\n",
      "Loss: 38.131535\n",
      "Loss: 38.015543\n",
      "Loss: 37.938446\n",
      "Loss: 37.901292\n",
      "Loss: 37.837915\n",
      "Loss: 37.702247\n",
      "Loss: 37.555606\n",
      "Loss: 37.446312\n",
      "Loss: 37.380190\n",
      "Loss: 37.350669\n",
      "Loss: 37.276284\n",
      "Loss: 37.128854\n",
      "Loss: 36.987070\n",
      "Loss: 36.885300\n",
      "Loss: 36.830974\n",
      "Loss: 36.809212\n",
      "Loss: 36.721050\n",
      "Loss: 36.563153\n",
      "Loss: 36.428346\n",
      "Loss: 36.330922\n",
      "Loss: 36.291313\n",
      "Loss: 36.276564\n",
      "Loss: 36.172750\n",
      "Loss: 36.006519\n",
      "Loss: 35.877229\n",
      "Loss: 35.786941\n",
      "Loss: 35.760592\n",
      "Loss: 35.751931\n",
      "Loss: 35.627759\n",
      "Loss: 35.457940\n",
      "Loss: 35.342349\n",
      "Loss: 35.249657\n",
      "Loss: 35.244988\n",
      "Loss: 35.237013\n",
      "Loss: 35.089636\n",
      "Loss: 34.929374\n",
      "Loss: 34.810882\n",
      "Loss: 34.741083\n",
      "Loss: 34.768436\n",
      "Loss: 34.725900\n",
      "Loss: 34.552267\n",
      "Loss: 34.411763\n",
      "Loss: 34.344542\n",
      "Loss: 34.290626\n",
      "Loss: 34.313057\n",
      "Loss: 34.197576\n",
      "Loss: 34.085122\n",
      "Loss: 34.080710\n",
      "Loss: 33.969742\n",
      "Loss: 33.949087\n",
      "Loss: 33.909062\n",
      "Loss: 33.880370\n",
      "Loss: 33.660569\n",
      "Loss: 33.467596\n",
      "Loss: 33.391621\n",
      "Loss: 33.336191\n",
      "Loss: 33.239615\n",
      "Loss: 33.082495\n",
      "Loss: 32.953181\n",
      "Loss: 32.911621\n",
      "Loss: 32.828712\n",
      "Loss: 32.723249\n",
      "Loss: 32.615809\n",
      "Loss: 32.514942\n",
      "Loss: 32.463274\n",
      "Loss: 32.398903\n",
      "Loss: 32.313573\n",
      "Loss: 32.197287\n",
      "Loss: 32.096590\n",
      "Loss: 32.027254\n",
      "Loss: 31.992129\n",
      "Loss: 31.941906\n",
      "Loss: 31.829216\n",
      "Loss: 31.703802\n",
      "Loss: 31.602230\n",
      "Loss: 31.536105\n",
      "Loss: 31.523664\n",
      "Loss: 31.489100\n",
      "Loss: 31.363083\n",
      "Loss: 31.224490\n",
      "Loss: 31.119531\n",
      "Loss: 31.046497\n",
      "Loss: 31.058096\n",
      "Loss: 31.053506\n",
      "Loss: 30.911832\n",
      "Loss: 30.756733\n",
      "Loss: 30.653107\n",
      "Loss: 30.564748\n",
      "Loss: 30.594209\n",
      "Loss: 30.619742\n",
      "Loss: 30.460561\n",
      "Loss: 30.293528\n",
      "Loss: 30.205210\n",
      "Loss: 30.096040\n",
      "Loss: 30.108759\n",
      "Loss: 30.158269\n",
      "Loss: 30.015040\n",
      "Loss: 29.828580\n",
      "Loss: 29.752618\n",
      "Loss: 29.645415\n",
      "Loss: 29.581523\n",
      "Loss: 29.636987\n",
      "Loss: 29.609631\n",
      "Loss: 29.435644\n",
      "Loss: 29.277674\n",
      "Loss: 29.218089\n",
      "Loss: 29.121660\n",
      "Loss: 29.018964\n",
      "Loss: 29.050984\n",
      "Loss: 29.099083\n",
      "Loss: 29.024206\n",
      "Loss: 28.829765\n",
      "Loss: 28.709810\n",
      "Loss: 28.718849\n",
      "Loss: 28.517628\n",
      "Loss: 28.453074\n",
      "Loss: 28.516447\n",
      "Loss: 28.485649\n",
      "Loss: 28.285921\n",
      "Loss: 28.181704\n",
      "Loss: 28.171439\n",
      "Loss: 27.997132\n",
      "Loss: 27.963598\n",
      "Loss: 27.995822\n",
      "Loss: 28.004860\n",
      "Loss: 27.959302\n",
      "Loss: 27.909752\n",
      "Loss: 27.720363\n",
      "Loss: 27.562449\n",
      "Loss: 27.585109\n",
      "Loss: 27.409294\n",
      "Loss: 27.266134\n",
      "Loss: 27.304044\n",
      "Loss: 27.280587\n",
      "Loss: 27.183116\n",
      "Loss: 27.089980\n",
      "Loss: 26.962276\n",
      "Loss: 26.824720\n",
      "Loss: 26.779796\n",
      "Loss: 26.801264\n",
      "Loss: 26.612853\n",
      "Loss: 26.538129\n",
      "Loss: 26.616297\n",
      "Loss: 26.667766\n",
      "Loss: 26.551982\n",
      "Loss: 26.321262\n",
      "Loss: 26.243622\n",
      "Loss: 26.268340\n",
      "Loss: 26.060076\n",
      "Loss: 26.042627\n",
      "Loss: 26.003786\n",
      "Loss: 25.845564\n",
      "Loss: 25.795266\n",
      "Loss: 25.702557\n",
      "Loss: 25.640968\n",
      "Loss: 25.821685\n",
      "Loss: 25.855671\n",
      "Loss: 25.554367\n",
      "Loss: 25.388893\n",
      "Loss: 25.437693\n",
      "Loss: 25.248151\n",
      "Loss: 25.270000\n",
      "Loss: 25.190805\n",
      "Loss: 25.044705\n",
      "Loss: 25.046522\n",
      "Loss: 24.893892\n",
      "Loss: 25.018982\n",
      "Loss: 25.130485\n",
      "Loss: 24.861597\n",
      "Loss: 24.746087\n",
      "Loss: 24.691694\n",
      "Loss: 24.598882\n",
      "Loss: 24.717749\n",
      "Loss: 24.506016\n",
      "Loss: 24.522222\n",
      "Loss: 24.336784\n",
      "Loss: 24.372546\n",
      "Loss: 24.425304\n",
      "Loss: 24.190367\n",
      "Loss: 24.259929\n",
      "Loss: 23.999487\n",
      "Loss: 24.111452\n",
      "Loss: 23.971027\n",
      "Loss: 23.858283\n",
      "Loss: 23.740795\n",
      "Loss: 23.642113\n",
      "Loss: 23.690743\n",
      "Loss: 23.533047\n",
      "Loss: 23.468540\n",
      "Loss: 23.323100\n",
      "Loss: 23.337488\n",
      "Loss: 23.382900\n",
      "Loss: 23.188760\n",
      "Loss: 23.119965\n",
      "Loss: 23.009492\n",
      "Loss: 23.054295\n",
      "Loss: 23.151048\n",
      "Loss: 22.913947\n",
      "Loss: 22.850712\n",
      "Loss: 22.741614\n",
      "Loss: 22.785679\n",
      "Loss: 22.881433\n",
      "Loss: 22.620786\n",
      "Loss: 22.609150\n",
      "Loss: 22.454115\n",
      "Loss: 22.559321\n",
      "Loss: 22.521639\n",
      "Loss: 22.310099\n",
      "Loss: 22.282790\n",
      "Loss: 22.147412\n",
      "Loss: 22.271450\n",
      "Loss: 22.114898\n",
      "Loss: 21.994326\n",
      "Loss: 21.890141\n",
      "Loss: 21.856443\n",
      "Loss: 21.934398\n",
      "Loss: 21.750530\n",
      "Loss: 21.666455\n",
      "Loss: 21.560547\n",
      "Loss: 21.597985\n",
      "Loss: 21.667931\n",
      "Loss: 21.448949\n",
      "Loss: 21.381338\n",
      "Loss: 21.277471\n",
      "Loss: 21.364397\n",
      "Loss: 21.418521\n",
      "Loss: 21.167833\n",
      "Loss: 21.136292\n",
      "Loss: 21.013732\n",
      "Loss: 21.164741\n",
      "Loss: 21.111147\n",
      "Loss: 20.891892\n",
      "Loss: 20.857457\n",
      "Loss: 20.755948\n",
      "Loss: 20.922141\n",
      "Loss: 20.735054\n",
      "Loss: 20.623246\n",
      "Loss: 20.512860\n",
      "Loss: 20.523938\n",
      "Loss: 20.574032\n",
      "Loss: 20.372367\n",
      "Loss: 20.308526\n",
      "Loss: 20.201775\n",
      "Loss: 20.307550\n",
      "Loss: 20.260424\n",
      "Loss: 20.067995\n",
      "Loss: 20.009101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 19.937991\n",
      "Loss: 20.106374\n",
      "Loss: 19.977114\n",
      "Loss: 19.808977\n",
      "Loss: 19.745293\n",
      "Loss: 19.722482\n",
      "Loss: 19.900511\n",
      "Loss: 19.675684\n",
      "Loss: 19.585499\n",
      "Loss: 19.478837\n",
      "Loss: 19.570855\n",
      "Loss: 19.600922\n",
      "Loss: 19.368862\n",
      "Loss: 19.317212\n",
      "Loss: 19.218243\n",
      "Loss: 19.378873\n",
      "Loss: 19.215964\n",
      "Loss: 19.090013\n",
      "Loss: 18.983535\n",
      "Loss: 19.013165\n",
      "Loss: 19.062833\n",
      "Loss: 18.868313\n",
      "Loss: 18.790213\n",
      "Loss: 18.701075\n",
      "Loss: 18.835663\n",
      "Loss: 18.773176\n",
      "Loss: 18.587718\n",
      "Loss: 18.516996\n",
      "Loss: 18.477811\n",
      "Loss: 18.667801\n",
      "Loss: 18.496775\n",
      "Loss: 18.358619\n",
      "Loss: 18.272871\n",
      "Loss: 18.328210\n",
      "Loss: 18.459514\n",
      "Loss: 18.205742\n",
      "Loss: 18.144464\n",
      "Loss: 18.030474\n",
      "Loss: 18.232068\n",
      "Loss: 18.123377\n",
      "Loss: 17.950159\n",
      "Loss: 17.851080\n",
      "Loss: 17.852089\n",
      "Loss: 17.957863\n",
      "Loss: 17.748775\n",
      "Loss: 17.658805\n",
      "Loss: 17.561164\n",
      "Loss: 17.692089\n",
      "Loss: 17.613293\n",
      "Loss: 17.447557\n",
      "Loss: 17.360018\n",
      "Loss: 17.348560\n",
      "Loss: 17.493288\n",
      "Loss: 17.322845\n",
      "Loss: 17.199537\n",
      "Loss: 17.111642\n",
      "Loss: 17.193750\n",
      "Loss: 17.304495\n",
      "Loss: 17.065448\n",
      "Loss: 16.991955\n",
      "Loss: 16.891119\n",
      "Loss: 17.092202\n",
      "Loss: 17.068630\n",
      "Loss: 16.838745\n",
      "Loss: 16.780284\n",
      "Loss: 16.712348\n",
      "Loss: 16.959492\n",
      "Loss: 16.740862\n",
      "Loss: 16.632246\n",
      "Loss: 16.510924\n",
      "Loss: 16.625729\n",
      "Loss: 16.635639\n",
      "Loss: 16.430933\n",
      "Loss: 16.338733\n",
      "Loss: 16.280080\n",
      "Loss: 16.432104\n",
      "Loss: 16.275797\n",
      "Loss: 16.154979\n",
      "Loss: 16.055822\n",
      "Loss: 16.121903\n",
      "Loss: 16.183571\n",
      "Loss: 15.989200\n",
      "Loss: 15.908225\n",
      "Loss: 15.824674\n",
      "Loss: 15.980102\n",
      "Loss: 15.963198\n",
      "Loss: 15.758592\n",
      "Loss: 15.701175\n",
      "Loss: 15.629175\n",
      "Loss: 15.858023\n",
      "Loss: 15.739110\n",
      "Loss: 15.569595\n",
      "Loss: 15.507192\n",
      "Loss: 15.487497\n",
      "Loss: 15.722455\n",
      "Loss: 15.481054\n",
      "Loss: 15.404781\n",
      "Loss: 15.282685\n",
      "Loss: 15.434627\n",
      "Loss: 15.462192\n",
      "Loss: 15.241547\n",
      "Loss: 15.165730\n",
      "Loss: 15.088859\n",
      "Loss: 15.287353\n",
      "Loss: 15.105915\n",
      "Loss: 15.004167\n",
      "Loss: 14.883695\n",
      "Loss: 14.980905\n",
      "Loss: 14.989412\n",
      "Loss: 14.816648\n",
      "Loss: 14.732356\n",
      "Loss: 14.672662\n",
      "Loss: 14.823667\n",
      "Loss: 14.712019\n",
      "Loss: 14.587638\n",
      "Loss: 14.500435\n",
      "Loss: 14.525577\n",
      "Loss: 14.662154\n",
      "Loss: 14.475420\n",
      "Loss: 14.398050\n",
      "Loss: 14.298263\n",
      "Loss: 14.419633\n",
      "Loss: 14.499782\n",
      "Loss: 14.273008\n",
      "Loss: 14.236453\n",
      "Loss: 14.118498\n",
      "Loss: 14.360399\n",
      "Loss: 14.290104\n",
      "Loss: 14.118579\n",
      "Loss: 14.051614\n",
      "Loss: 14.013591\n",
      "Loss: 14.246051\n",
      "Loss: 14.015725\n",
      "Loss: 13.957724\n",
      "Loss: 13.812481\n",
      "Loss: 13.998491\n",
      "Loss: 13.938527\n",
      "Loss: 13.793697\n",
      "Loss: 13.675586\n",
      "Loss: 13.676748\n",
      "Loss: 13.776608\n",
      "Loss: 13.618375\n",
      "Loss: 13.528532\n",
      "Loss: 13.436391\n",
      "Loss: 13.565802\n",
      "Loss: 13.501573\n",
      "Loss: 13.377352\n",
      "Loss: 13.286405\n",
      "Loss: 13.294193\n",
      "Loss: 13.414467\n",
      "Loss: 13.270497\n",
      "Loss: 13.189266\n",
      "Loss: 13.093471\n",
      "Loss: 13.204643\n",
      "Loss: 13.276982\n",
      "Loss: 13.084264\n",
      "Loss: 13.040551\n",
      "Loss: 12.931941\n",
      "Loss: 13.165518\n",
      "Loss: 13.115267\n",
      "Loss: 12.953036\n",
      "Loss: 12.894561\n",
      "Loss: 12.846830\n",
      "Loss: 13.116780\n",
      "Loss: 12.891238\n",
      "Loss: 12.850262\n",
      "Loss: 12.687892\n",
      "Loss: 12.905467\n",
      "Loss: 12.848397\n",
      "Loss: 12.717926\n",
      "Loss: 12.578601\n",
      "Loss: 12.605894\n",
      "Loss: 12.672805\n",
      "Loss: 12.533010\n",
      "Loss: 12.415167\n",
      "Loss: 12.362924\n",
      "Loss: 12.461830\n",
      "Loss: 12.357218\n",
      "Loss: 12.255902\n",
      "Loss: 12.172892\n",
      "Loss: 12.251177\n",
      "Loss: 12.241723\n",
      "Loss: 12.127404\n",
      "Loss: 12.048505\n",
      "Loss: 12.024336\n",
      "Loss: 12.151133\n",
      "Loss: 12.074108\n",
      "Loss: 11.967253\n",
      "Loss: 11.889401\n",
      "Loss: 11.916559\n",
      "Loss: 12.089556\n",
      "Loss: 11.928766\n",
      "Loss: 11.863258\n",
      "Loss: 11.756977\n",
      "Loss: 11.876213\n",
      "Loss: 12.041330\n",
      "Loss: 11.802043\n",
      "Loss: 11.811812\n",
      "Loss: 11.630883\n",
      "Loss: 11.975865\n",
      "Loss: 11.871571\n",
      "Loss: 11.770941\n",
      "Loss: 11.634841\n",
      "Loss: 11.711043\n",
      "Loss: 11.791183\n",
      "Loss: 11.643070\n",
      "Loss: 11.479191\n",
      "Loss: 11.471638\n",
      "Loss: 11.509283\n",
      "Loss: 11.404683\n",
      "Loss: 11.256864\n",
      "Loss: 11.252466\n",
      "Loss: 11.261563\n",
      "Loss: 11.187352\n",
      "Loss: 11.093714\n",
      "Loss: 11.072219\n",
      "Loss: 11.097127\n",
      "Loss: 11.055341\n",
      "Loss: 10.982321\n",
      "Loss: 10.931361\n",
      "Loss: 10.940608\n",
      "Loss: 10.971657\n",
      "Loss: 10.909701\n",
      "Loss: 10.834400\n",
      "Loss: 10.781467\n",
      "Loss: 10.812694\n",
      "Loss: 10.874695\n",
      "Loss: 10.788196\n",
      "Loss: 10.708433\n",
      "Loss: 10.645495\n",
      "Loss: 10.663997\n",
      "Loss: 10.800737\n",
      "Loss: 10.704935\n",
      "Loss: 10.604318\n",
      "Loss: 10.557710\n",
      "Loss: 10.496068\n",
      "Loss: 10.728766\n",
      "Loss: 10.663713\n",
      "Loss: 10.513523\n",
      "Loss: 10.530072\n",
      "Loss: 10.359721\n",
      "Loss: 10.701480\n",
      "Loss: 10.631377\n",
      "Loss: 10.483017\n",
      "Loss: 10.537334\n",
      "Loss: 10.322167\n",
      "Loss: 10.835046\n",
      "Loss: 10.530149\n",
      "Loss: 10.631054\n",
      "Loss: 10.357211\n",
      "Loss: 10.728795\n",
      "Loss: 10.570702\n",
      "Loss: 10.482759\n",
      "Loss: 10.264753\n",
      "Loss: 10.361252\n",
      "Loss: 10.201852\n",
      "Loss: 10.055877\n",
      "Loss: 10.003806\n",
      "Loss: 9.962215\n",
      "Loss: 9.916280\n",
      "Loss: 9.862318\n",
      "Loss: 9.876006\n",
      "Loss: 9.826729\n",
      "Loss: 9.775456\n",
      "Loss: 9.760975\n",
      "Loss: 9.773753\n",
      "Loss: 9.728709\n",
      "Loss: 9.670041\n",
      "Loss: 9.641866\n",
      "Loss: 9.656210\n",
      "Loss: 9.647784\n",
      "Loss: 9.592513\n",
      "Loss: 9.541336\n",
      "Loss: 9.516593\n",
      "Loss: 9.551470\n",
      "Loss: 9.544926\n",
      "Loss: 9.475717\n",
      "Loss: 9.421956\n",
      "Loss: 9.386635\n",
      "Loss: 9.443765\n",
      "Loss: 9.462113\n",
      "Loss: 9.375571\n",
      "Loss: 9.322615\n",
      "Loss: 9.260834\n",
      "Loss: 9.305215\n",
      "Loss: 9.389285\n",
      "Loss: 9.298635\n",
      "Loss: 9.230206\n",
      "Loss: 9.172425\n",
      "Loss: 9.137127\n",
      "Loss: 9.273944\n",
      "Loss: 9.247389\n",
      "Loss: 9.131288\n",
      "Loss: 9.103390\n",
      "Loss: 9.005989\n",
      "Loss: 9.093015\n",
      "Loss: 9.184738\n",
      "Loss: 9.052857\n",
      "Loss: 9.007347\n",
      "Loss: 8.934076\n",
      "Loss: 8.902384\n",
      "Loss: 9.066217\n",
      "Loss: 9.001329\n",
      "Loss: 8.895711\n",
      "Loss: 8.872880\n",
      "Loss: 8.762148\n",
      "Loss: 8.892915\n",
      "Loss: 8.947697\n",
      "Loss: 8.802539\n",
      "Loss: 8.786389\n",
      "Loss: 8.680629\n",
      "Loss: 8.706105\n",
      "Loss: 8.862545\n",
      "Loss: 8.737194\n",
      "Loss: 8.680186\n",
      "Loss: 8.625639\n",
      "Loss: 8.546360\n",
      "Loss: 8.741593\n",
      "Loss: 8.687700\n",
      "Loss: 8.576058\n",
      "Loss: 8.569940\n",
      "Loss: 8.427829\n",
      "Loss: 8.609949\n",
      "Loss: 8.644136\n",
      "Loss: 8.487003\n",
      "Loss: 8.516687\n",
      "Loss: 8.340235\n",
      "Loss: 8.510240\n",
      "Loss: 8.612940\n",
      "Loss: 8.417795\n",
      "Loss: 8.502389\n",
      "Loss: 8.262452\n",
      "Loss: 8.529772\n",
      "Loss: 8.595793\n",
      "Loss: 8.425612\n",
      "Loss: 8.569278\n",
      "Loss: 8.221906\n",
      "Loss: 8.825645\n",
      "Loss: 8.525537\n",
      "Loss: 8.780508\n",
      "Loss: 8.414668\n",
      "Loss: 8.856048\n",
      "Loss: 8.686650\n",
      "Loss: 8.552468\n",
      "Loss: 8.406753\n",
      "Loss: 8.333311\n",
      "Loss: 8.295669\n",
      "Loss: 8.065626\n",
      "Loss: 8.090627\n",
      "Loss: 7.998444\n",
      "Loss: 7.948618\n",
      "Loss: 7.983370\n",
      "Loss: 7.943587\n",
      "Loss: 7.882124\n",
      "Loss: 7.861781\n",
      "Loss: 7.884974\n",
      "Loss: 7.836993\n",
      "Loss: 7.781178\n",
      "Loss: 7.785808\n",
      "Loss: 7.789455\n",
      "Loss: 7.745232\n",
      "Loss: 7.697299\n",
      "Loss: 7.702738\n",
      "Loss: 7.707942\n",
      "Loss: 7.669103\n",
      "Loss: 7.626188\n",
      "Loss: 7.615309\n",
      "Loss: 7.632175\n",
      "Loss: 7.610480\n",
      "Loss: 7.566824\n",
      "Loss: 7.533495\n",
      "Loss: 7.545817\n",
      "Loss: 7.563492\n",
      "Loss: 7.521587\n",
      "Loss: 7.476363\n",
      "Loss: 7.445446\n",
      "Loss: 7.493317\n",
      "Loss: 7.498659\n",
      "Loss: 7.441197\n",
      "Loss: 7.393766\n",
      "Loss: 7.364109\n",
      "Loss: 7.460963\n",
      "Loss: 7.440046\n",
      "Loss: 7.379637\n",
      "Loss: 7.325453\n",
      "Loss: 7.294477\n",
      "Loss: 7.459715\n",
      "Loss: 7.387993\n",
      "Loss: 7.353490\n",
      "Loss: 7.272706\n",
      "Loss: 7.265632\n",
      "Loss: 7.500830\n",
      "Loss: 7.341798\n",
      "Loss: 7.398702\n",
      "Loss: 7.206180\n",
      "Loss: 7.405206\n",
      "Loss: 7.505473\n",
      "Loss: 7.399357\n",
      "Loss: 7.403391\n",
      "Loss: 7.242266\n",
      "Loss: 7.587243\n",
      "Loss: 7.432117\n",
      "Loss: 7.336843\n",
      "Loss: 7.253357\n",
      "Loss: 7.374009\n",
      "Loss: 7.308474\n",
      "Loss: 7.084789\n",
      "Loss: 7.126669\n",
      "Loss: 7.080002\n",
      "Loss: 7.023321\n",
      "Loss: 6.944976\n",
      "Loss: 6.982761\n",
      "Loss: 6.946467\n",
      "Loss: 6.887689\n",
      "Loss: 6.874842\n",
      "Loss: 6.897006\n",
      "Loss: 6.865032\n",
      "Loss: 6.815933\n",
      "Loss: 6.809649\n",
      "Loss: 6.827808\n",
      "Loss: 6.801838\n",
      "Loss: 6.759172\n",
      "Loss: 6.743623\n",
      "Loss: 6.762831\n",
      "Loss: 6.750163\n",
      "Loss: 6.710833\n",
      "Loss: 6.681180\n",
      "Loss: 6.693875\n",
      "Loss: 6.705053\n",
      "Loss: 6.670817\n",
      "Loss: 6.631058\n",
      "Loss: 6.617539\n",
      "Loss: 6.653117\n",
      "Loss: 6.640493\n",
      "Loss: 6.597340\n",
      "Loss: 6.555209\n",
      "Loss: 6.570155\n",
      "Loss: 6.615125\n",
      "Loss: 6.575720\n",
      "Loss: 6.531786\n",
      "Loss: 6.483388\n",
      "Loss: 6.542821\n",
      "Loss: 6.578336\n",
      "Loss: 6.520163\n",
      "Loss: 6.476022\n",
      "Loss: 6.420187\n",
      "Loss: 6.542282\n",
      "Loss: 6.541005\n",
      "Loss: 6.484811\n",
      "Loss: 6.426478\n",
      "Loss: 6.383678\n",
      "Loss: 6.571351\n",
      "Loss: 6.498668\n",
      "Loss: 6.478580\n",
      "Loss: 6.362131\n",
      "Loss: 6.433494\n",
      "Loss: 6.577954\n",
      "Loss: 6.478760\n",
      "Loss: 6.441188\n",
      "Loss: 6.315711\n",
      "Loss: 6.550083\n",
      "Loss: 6.485756\n",
      "Loss: 6.426297\n",
      "Loss: 6.295012\n",
      "Loss: 6.439759\n",
      "Loss: 6.416420\n",
      "Loss: 6.349613\n",
      "Loss: 6.216544\n",
      "Loss: 6.327654\n",
      "Loss: 6.294236\n",
      "Loss: 6.232603\n",
      "Loss: 6.138532\n",
      "Loss: 6.233601\n",
      "Loss: 6.199967\n",
      "Loss: 6.137156\n",
      "Loss: 6.078888\n",
      "Loss: 6.163998\n",
      "Loss: 6.133433\n",
      "Loss: 6.069002\n",
      "Loss: 6.022383\n",
      "Loss: 6.102534\n",
      "Loss: 6.077826\n",
      "Loss: 6.014985\n",
      "Loss: 5.964422\n",
      "Loss: 6.038920\n",
      "Loss: 6.025577\n",
      "Loss: 5.967642\n",
      "Loss: 5.907119\n",
      "Loss: 5.968845\n",
      "Loss: 5.974536\n",
      "Loss: 5.923029\n",
      "Loss: 5.855107\n",
      "Loss: 5.890513\n",
      "Loss: 5.921927\n",
      "Loss: 5.878885\n",
      "Loss: 5.812371\n",
      "Loss: 5.808744\n",
      "Loss: 5.859736\n",
      "Loss: 5.835217\n",
      "Loss: 5.778228\n",
      "Loss: 5.738564\n",
      "Loss: 5.777747\n",
      "Loss: 5.790749\n",
      "Loss: 5.747000\n",
      "Loss: 5.694229\n",
      "Loss: 5.686442\n",
      "Loss: 5.728399\n",
      "Loss: 5.716092\n",
      "Loss: 5.669579\n",
      "Loss: 5.625927\n",
      "Loss: 5.634168\n",
      "Loss: 5.671973\n",
      "Loss: 5.649927\n",
      "Loss: 5.604175\n",
      "Loss: 5.563229\n",
      "Loss: 5.578552\n",
      "Loss: 5.618490\n",
      "Loss: 5.592130\n",
      "Loss: 5.546878\n",
      "Loss: 5.503067\n",
      "Loss: 5.520336\n",
      "Loss: 5.568350\n",
      "Loss: 5.540529\n",
      "Loss: 5.495512\n",
      "Loss: 5.446078\n",
      "Loss: 5.459143\n",
      "Loss: 5.520263\n",
      "Loss: 5.494101\n",
      "Loss: 5.448983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 5.393986\n",
      "Loss: 5.395871\n",
      "Loss: 5.472912\n",
      "Loss: 5.452054\n",
      "Loss: 5.405854\n",
      "Loss: 5.347333\n",
      "Loss: 5.333269\n",
      "Loss: 5.425344\n",
      "Loss: 5.413004\n",
      "Loss: 5.364598\n",
      "Loss: 5.304105\n",
      "Loss: 5.274659\n",
      "Loss: 5.378449\n",
      "Loss: 5.374545\n",
      "Loss: 5.323819\n",
      "Loss: 5.260140\n",
      "Loss: 5.222236\n",
      "Loss: 5.334497\n",
      "Loss: 5.333264\n",
      "Loss: 5.281254\n",
      "Loss: 5.210564\n",
      "Loss: 5.177295\n",
      "Loss: 5.293789\n",
      "Loss: 5.285748\n",
      "Loss: 5.232387\n",
      "Loss: 5.152078\n",
      "Loss: 5.141532\n",
      "Loss: 5.250770\n",
      "Loss: 5.230339\n",
      "Loss: 5.170860\n",
      "Loss: 5.087346\n",
      "Loss: 5.114068\n",
      "Loss: 5.196933\n",
      "Loss: 5.167076\n",
      "Loss: 5.095177\n",
      "Loss: 5.026765\n",
      "Loss: 5.086002\n",
      "Loss: 5.131673\n",
      "Loss: 5.095027\n",
      "Loss: 5.015304\n",
      "Loss: 4.978155\n",
      "Loss: 5.047979\n",
      "Loss: 5.063662\n",
      "Loss: 5.017975\n",
      "Loss: 4.943781\n",
      "Loss: 4.937977\n",
      "Loss: 5.001747\n",
      "Loss: 4.999144\n",
      "Loss: 4.945717\n",
      "Loss: 4.883619\n",
      "Loss: 4.899856\n",
      "Loss: 4.954028\n",
      "Loss: 4.939670\n",
      "Loss: 4.882688\n",
      "Loss: 4.830983\n",
      "Loss: 4.861846\n",
      "Loss: 4.908516\n",
      "Loss: 4.885742\n",
      "Loss: 4.827278\n",
      "Loss: 4.782136\n",
      "Loss: 4.824460\n",
      "Loss: 4.866213\n",
      "Loss: 4.837109\n",
      "Loss: 4.776955\n",
      "Loss: 4.735291\n",
      "Loss: 4.788572\n",
      "Loss: 4.827302\n",
      "Loss: 4.793063\n",
      "Loss: 4.730020\n",
      "Loss: 4.690047\n",
      "Loss: 4.755271\n",
      "Loss: 4.791667\n",
      "Loss: 4.752750\n",
      "Loss: 4.685183\n",
      "Loss: 4.646964\n",
      "Loss: 4.725947\n",
      "Loss: 4.758634\n",
      "Loss: 4.714951\n",
      "Loss: 4.640802\n",
      "Loss: 4.607694\n",
      "Loss: 4.701825\n",
      "Loss: 4.726643\n",
      "Loss: 4.677259\n",
      "Loss: 4.594546\n",
      "Loss: 4.575525\n",
      "Loss: 4.682246\n",
      "Loss: 4.693268\n",
      "Loss: 4.634592\n",
      "Loss: 4.544467\n",
      "Loss: 4.555235\n",
      "Loss: 4.661507\n",
      "Loss: 4.655774\n",
      "Loss: 4.578708\n",
      "Loss: 4.493187\n",
      "Loss: 4.547874\n",
      "Loss: 4.628899\n",
      "Loss: 4.608272\n",
      "Loss: 4.505341\n",
      "Loss: 4.452047\n",
      "Loss: 4.540203\n",
      "Loss: 4.579594\n",
      "Loss: 4.536160\n",
      "Loss: 4.427026\n",
      "Loss: 4.429905\n",
      "Loss: 4.512465\n",
      "Loss: 4.519922\n",
      "Loss: 4.440352\n",
      "Loss: 4.365569\n",
      "Loss: 4.414681\n",
      "Loss: 4.465895\n",
      "Loss: 4.447764\n",
      "Loss: 4.352175\n",
      "Loss: 4.326691\n",
      "Loss: 4.390871\n",
      "Loss: 4.414003\n",
      "Loss: 4.366840\n",
      "Loss: 4.287195\n",
      "Loss: 4.300503\n",
      "Loss: 4.359903\n",
      "Loss: 4.361477\n",
      "Loss: 4.294008\n",
      "Loss: 4.239499\n",
      "Loss: 4.279296\n",
      "Loss: 4.327665\n",
      "Loss: 4.309386\n",
      "Loss: 4.233858\n",
      "Loss: 4.202175\n",
      "Loss: 4.261421\n",
      "Loss: 4.296137\n",
      "Loss: 4.259470\n",
      "Loss: 4.182602\n",
      "Loss: 4.173496\n",
      "Loss: 4.247203\n",
      "Loss: 4.265933\n",
      "Loss: 4.211843\n",
      "Loss: 4.137111\n",
      "Loss: 4.155262\n",
      "Loss: 4.235773\n",
      "Loss: 4.236955\n",
      "Loss: 4.164334\n",
      "Loss: 4.097359\n",
      "Loss: 4.150123\n",
      "Loss: 4.223726\n",
      "Loss: 4.206610\n",
      "Loss: 4.113486\n",
      "Loss: 4.068101\n",
      "Loss: 4.155849\n",
      "Loss: 4.205432\n",
      "Loss: 4.164465\n",
      "Loss: 4.058421\n",
      "Loss: 4.058561\n",
      "Loss: 4.157668\n",
      "Loss: 4.177433\n",
      "Loss: 4.094255\n",
      "Loss: 4.009520\n",
      "Loss: 4.067752\n",
      "Loss: 4.137235\n",
      "Loss: 4.127560\n",
      "Loss: 4.006111\n",
      "Loss: 3.985703\n",
      "Loss: 4.066795\n",
      "Loss: 4.096712\n",
      "Loss: 4.031018\n",
      "Loss: 3.939165\n",
      "Loss: 3.980941\n",
      "Loss: 4.036793\n",
      "Loss: 4.033544\n",
      "Loss: 3.929370\n",
      "Loss: 3.908288\n",
      "Loss: 3.968892\n",
      "Loss: 3.994719\n",
      "Loss: 3.943542\n",
      "Loss: 3.867048\n",
      "Loss: 3.894444\n",
      "Loss: 3.944056\n",
      "Loss: 3.942393\n",
      "Loss: 3.864428\n",
      "Loss: 3.834020\n",
      "Loss: 3.883596\n",
      "Loss: 3.915673\n",
      "Loss: 3.882470\n",
      "Loss: 3.809701\n",
      "Loss: 3.815374\n",
      "Loss: 3.872316\n",
      "Loss: 3.884670\n",
      "Loss: 3.825266\n",
      "Loss: 3.771200\n",
      "Loss: 3.807040\n",
      "Loss: 3.861391\n",
      "Loss: 3.851052\n",
      "Loss: 3.775017\n",
      "Loss: 3.744836\n",
      "Loss: 3.808080\n",
      "Loss: 3.850126\n",
      "Loss: 3.814068\n",
      "Loss: 3.731637\n",
      "Loss: 3.733436\n",
      "Loss: 3.815628\n",
      "Loss: 3.837397\n",
      "Loss: 3.770396\n",
      "Loss: 3.696672\n",
      "Loss: 3.742099\n",
      "Loss: 3.822016\n",
      "Loss: 3.818980\n",
      "Loss: 3.717170\n",
      "Loss: 3.678238\n",
      "Loss: 3.765128\n",
      "Loss: 3.817612\n",
      "Loss: 3.773967\n",
      "Loss: 3.662615\n",
      "Loss: 3.686766\n",
      "Loss: 3.774110\n",
      "Loss: 3.795533\n",
      "Loss: 3.683896\n",
      "Loss: 3.631706\n",
      "Loss: 3.705158\n",
      "Loss: 3.754137\n",
      "Loss: 3.719146\n",
      "Loss: 3.601493\n",
      "Loss: 3.630879\n",
      "Loss: 3.692293\n",
      "Loss: 3.707610\n",
      "Loss: 3.600681\n",
      "Loss: 3.570292\n",
      "Loss: 3.627368\n",
      "Loss: 3.658657\n",
      "Loss: 3.613406\n",
      "Loss: 3.532734\n",
      "Loss: 3.562391\n",
      "Loss: 3.607025\n",
      "Loss: 3.607296\n",
      "Loss: 3.527222\n",
      "Loss: 3.508527\n",
      "Loss: 3.555071\n",
      "Loss: 3.581045\n",
      "Loss: 3.541510\n",
      "Loss: 3.479131\n",
      "Loss: 3.498752\n",
      "Loss: 3.545208\n",
      "Loss: 3.548340\n",
      "Loss: 3.483763\n",
      "Loss: 3.452575\n",
      "Loss: 3.496344\n",
      "Loss: 3.534654\n",
      "Loss: 3.509677\n",
      "Loss: 3.439560\n",
      "Loss: 3.439240\n",
      "Loss: 3.500003\n",
      "Loss: 3.522636\n",
      "Loss: 3.468111\n",
      "Loss: 3.407220\n",
      "Loss: 3.440870\n",
      "Loss: 3.507961\n",
      "Loss: 3.508056\n",
      "Loss: 3.425702\n",
      "Loss: 3.388934\n",
      "Loss: 3.459443\n",
      "Loss: 3.515951\n",
      "Loss: 3.484302\n",
      "Loss: 3.385549\n",
      "Loss: 3.393007\n",
      "Loss: 3.485462\n",
      "Loss: 3.518103\n",
      "Loss: 3.433253\n",
      "Loss: 3.358401\n",
      "Loss: 3.422537\n",
      "Loss: 3.497075\n",
      "Loss: 3.493742\n",
      "Loss: 3.358575\n",
      "Loss: 3.360993\n",
      "Loss: 3.443214\n",
      "Loss: 3.484734\n",
      "Loss: 3.389848\n",
      "Loss: 3.314662\n",
      "Loss: 3.375890\n",
      "Loss: 3.424329\n",
      "Loss: 3.410154\n",
      "Loss: 3.285089\n",
      "Loss: 3.311045\n",
      "Loss: 3.361314\n",
      "Loss: 3.380149\n",
      "Loss: 3.283271\n",
      "Loss: 3.255764\n",
      "Loss: 3.303417\n",
      "Loss: 3.330705\n",
      "Loss: 3.290358\n",
      "Loss: 3.221965\n",
      "Loss: 3.249425\n",
      "Loss: 3.285967\n",
      "Loss: 3.284816\n",
      "Loss: 3.216068\n",
      "Loss: 3.203635\n",
      "Loss: 3.242724\n",
      "Loss: 3.265184\n",
      "Loss: 3.228671\n",
      "Loss: 3.176647\n",
      "Loss: 3.195957\n",
      "Loss: 3.236024\n",
      "Loss: 3.238421\n",
      "Loss: 3.179531\n",
      "Loss: 3.154951\n",
      "Loss: 3.194825\n",
      "Loss: 3.230011\n",
      "Loss: 3.205802\n",
      "Loss: 3.141019\n",
      "Loss: 3.145193\n",
      "Loss: 3.200909\n",
      "Loss: 3.223632\n",
      "Loss: 3.169201\n",
      "Loss: 3.113943\n",
      "Loss: 3.150114\n",
      "Loss: 3.213480\n",
      "Loss: 3.215461\n",
      "Loss: 3.130453\n",
      "Loss: 3.102641\n",
      "Loss: 3.172194\n",
      "Loss: 3.228922\n",
      "Loss: 3.196115\n",
      "Loss: 3.095378\n",
      "Loss: 3.115292\n",
      "Loss: 3.201965\n",
      "Loss: 3.240532\n",
      "Loss: 3.142016\n",
      "Loss: 3.079705\n",
      "Loss: 3.148971\n",
      "Loss: 3.218105\n",
      "Loss: 3.212961\n",
      "Loss: 3.067931\n",
      "Loss: 3.094423\n",
      "Loss: 3.162822\n",
      "Loss: 3.210357\n",
      "Loss: 3.087359\n",
      "Loss: 3.042604\n",
      "Loss: 3.102525\n",
      "Loss: 3.144318\n",
      "Loss: 3.108261\n",
      "Loss: 2.999973\n",
      "Loss: 3.043525\n",
      "Loss: 3.078979\n",
      "Loss: 3.089250\n",
      "Loss: 2.985812\n",
      "Loss: 2.989972\n",
      "Loss: 3.028499\n",
      "Loss: 3.049128\n",
      "Loss: 2.990478\n",
      "Loss: 2.950768\n",
      "Loss: 2.984070\n",
      "Loss: 3.010879\n",
      "Loss: 2.995144\n",
      "Loss: 2.934506\n",
      "Loss: 2.942597\n",
      "Loss: 2.975589\n",
      "Loss: 2.988531\n",
      "Loss: 2.941468\n",
      "Loss: 2.910022\n",
      "Loss: 2.936894\n",
      "Loss: 2.968926\n",
      "Loss: 2.959056\n",
      "Loss: 2.901912\n",
      "Loss: 2.896251\n",
      "Loss: 2.936390\n",
      "Loss: 2.963573\n",
      "Loss: 2.927576\n",
      "Loss: 2.873044\n",
      "Loss: 2.891216\n",
      "Loss: 2.943796\n",
      "Loss: 2.960331\n",
      "Loss: 2.896807\n",
      "Loss: 2.854767\n",
      "Loss: 2.899149\n",
      "Loss: 2.961241\n",
      "Loss: 2.959704\n",
      "Loss: 2.868808\n",
      "Loss: 2.851508\n",
      "Loss: 2.924361\n",
      "Loss: 2.987668\n",
      "Loss: 2.952699\n",
      "Loss: 2.845796\n",
      "Loss: 2.870419\n",
      "Loss: 2.958433\n",
      "Loss: 3.013783\n",
      "Loss: 2.906288\n",
      "Loss: 2.836263\n",
      "Loss: 2.903584\n",
      "Loss: 2.975977\n",
      "Loss: 2.990084\n",
      "Loss: 2.822277\n",
      "Loss: 2.848848\n",
      "Loss: 2.905929\n",
      "Loss: 2.967062\n",
      "Loss: 2.844608\n",
      "Loss: 2.786479\n",
      "Loss: 2.840285\n",
      "Loss: 2.877681\n",
      "Loss: 2.855414\n",
      "Loss: 2.743688\n",
      "Loss: 2.778623\n",
      "Loss: 2.808191\n",
      "Loss: 2.825018\n",
      "Loss: 2.739047\n",
      "Loss: 2.725903\n",
      "Loss: 2.758560\n",
      "Loss: 2.782320\n",
      "Loss: 2.749091\n",
      "Loss: 2.697816\n",
      "Loss: 2.713895\n",
      "Loss: 2.743600\n",
      "Loss: 2.750193\n",
      "Loss: 2.702193\n",
      "Loss: 2.677318\n",
      "Loss: 2.703138\n",
      "Loss: 2.732596\n",
      "Loss: 2.723621\n",
      "Loss: 2.671227\n",
      "Loss: 2.660746\n",
      "Loss: 2.696863\n",
      "Loss: 2.727587\n",
      "Loss: 2.704768\n",
      "Loss: 2.648255\n",
      "Loss: 2.647730\n",
      "Loss: 2.698591\n",
      "Loss: 2.731698\n",
      "Loss: 2.696376\n",
      "Loss: 2.632350\n",
      "Loss: 2.642298\n",
      "Loss: 2.712484\n",
      "Loss: 2.749394\n",
      "Loss: 2.699061\n",
      "Loss: 2.624582\n",
      "Loss: 2.651657\n",
      "Loss: 2.739624\n",
      "Loss: 2.780705\n",
      "Loss: 2.698935\n",
      "Loss: 2.624198\n",
      "Loss: 2.680047\n",
      "Loss: 2.767322\n",
      "Loss: 2.805348\n",
      "Loss: 2.656646\n",
      "Loss: 2.632883\n",
      "Loss: 2.699535\n",
      "Loss: 2.779148\n",
      "Loss: 2.735083\n",
      "Loss: 2.590228\n",
      "Loss: 2.634566\n",
      "Loss: 2.673097\n",
      "Loss: 2.733116\n",
      "Loss: 2.575662\n",
      "Loss: 2.566002\n",
      "Loss: 2.599515\n",
      "Loss: 2.645600\n",
      "Loss: 2.588771\n",
      "Loss: 2.510398\n",
      "Loss: 2.540771\n",
      "Loss: 2.568812\n",
      "Loss: 2.579191\n",
      "Loss: 2.501259\n",
      "Loss: 2.491523\n",
      "Loss: 2.519227\n",
      "Loss: 2.547310\n",
      "Loss: 2.519873\n",
      "Loss: 2.466043\n",
      "Loss: 2.475249\n",
      "Loss: 2.508231\n",
      "Loss: 2.527396\n",
      "Loss: 2.481951\n",
      "Loss: 2.442405\n",
      "Loss: 2.464358\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    Loss = np.zeros(ae_iters)\n",
    "    for i in range(ae_iters):\n",
    "        Ll = 0\n",
    "        for j in range(cell_len):\n",
    "            x, t, a = generate_batches(Data, Time, Assignments, j)\n",
    "            _, L = sess.run([optimizer, loss_ae], feed_dict = {lstm_ae.input: x, lstm_ae.time: t})\n",
    "            Ll += L\n",
    "        Loss[i] = Ll / cell_len\n",
    "        print('Loss: %f' %(Loss[i]))\n",
    "\n",
    "    assign_truth = []\n",
    "    data_reps = []\n",
    "    for c in range(cell_len):\n",
    "        data = np.transpose(Data[0][c])\n",
    "        time = np.transpose(Time[0][c])\n",
    "        assign = np.transpose(Assignments[0][c])\n",
    "        reps, cells = sess.run(lstm_ae.get_representation(), feed_dict = {lstm_ae.input: data, lstm_ae.time: time})\n",
    "        if c == 0:\n",
    "            data_reps = reps\n",
    "            assign_truth = assign\n",
    "        else:\n",
    "            data_reps = np.concatenate((data_reps, reps))\n",
    "            assign_truth = np.concatenate((assign_truth, assign))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'TLSTM')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "######## Clustering ##########################\n",
    "kmeans = KMeans(n_clusters = 4, random_state = 0, init = 'k-means++').fit(data_reps)\n",
    "centroid_values = kmeans.cluster_centers_\n",
    "\n",
    "#plt.figure(1)\n",
    "plt.scatter(data_reps[:, 0], data_reps[:, 1])\n",
    "plt.plot(centroid_values[:, 0], centroid_values[:, 1], 'kx', markersize = 35, alpha = 0.5)\n",
    "#, c = assign_truth, s = 50, I had to remove this code from the above line because it does not work in matplotlib 2.2.3\n",
    "plt.title('TLSTM')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(assign_truth)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Py2_ML",
   "language": "python",
   "name": "py2_ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
